<!doctype html>

<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="Saisyam&#39;s personal blog for technical articles" />
  <meta name="author" content="Saisyam" />
  <meta property="og:title" content="Effective Web Scraping with Python" />
<meta property="og:description" content="Web scraping is a process of automatically extracting information from websites. Web scrapers are small programs written to crawl and extract specific information from a webpage. For example, getting latest news items from news websites like BBC, CNN etc." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://saisyam.com/effective-web-scraping-with-python/" /><meta property="og:image" content="https://saisyam.com/webscraping.jpg" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-10T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2021-01-10T00:00:00&#43;00:00" />

 
  <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://saisyam.com/webscraping.jpg"/>

<meta name="twitter:title" content="Effective Web Scraping with Python"/>
<meta name="twitter:description" content="Web scraping is a process of automatically extracting information from websites. Web scrapers are small programs written to crawl and extract specific information from a webpage. For example, getting latest news items from news websites like BBC, CNN etc."/>

  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-50423294-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  <link rel="stylesheet" href="https://saisyam.com/css/pure-min.css" />
  <link rel="stylesheet" href="https://saisyam.com/css/grids-responsive-min.css" />
  <link rel="stylesheet" href="https://saisyam.com/css/style.css" />
  <style>
    #toc::before {
        content: "Table of Contents";
        font-weight: bold;
    }
    #toc nav {
      border-bottom: none;
      padding-bottom: 0.2em;
      font-family: "Ruda", sans-serif;
    }

    #toc nav ul {
       
      padding: 1em;
      list-style: decimal;
      display: inline-block;
    }
    ul.pagination {
      display: flex;
      justify-content: center;
      margin: 1em 0 0;
      padding: 0.5em 0;
      list-style: none;
    }
  
    ul.pagination li {
      padding: 0 1em;
    }
    .gist .blob-code-inner{ font-size:20px !important; }
    .gist .blob-num{ font-size:20px !important; }
  </style>
  <link rel="apple-touch-icon" sizes="180x180" href="favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">
  <link rel="manifest" href="favicon/site.webmanifest">
  <link rel="mask-icon" href="favicon/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
</head>

<body>
    <div id="layout" class="pure-g">
        

  <div class="content pure-u-1 pure-u-md-3-4">
    <div class="header">
      <a href="https://saisyam.com/"><h1 class="brand-title">Saisyam</h1></a>
        <h2 class="brand-tagline">Personal Blog</h2>
    </div>
    <div>
      <div class="posts">
        <h1 class="content-subhead"></h1>
        <section class="post">
            <header class="post-header">
                

                <h2 class="post-title">Effective Web Scraping with Python</h2>

                <p class="post-meta">
                  Under
                  <a class="post-category post-category-0" href="https://saisyam.com/categories/python/">Python</a>
                  
                </p>
            </header>

            <div class="post-description">
                <p>
                  <p>Web scraping is a process of automatically extracting information from websites. Web scrapers are small programs written to crawl and extract specific information from a webpage. For example, getting latest news items from news websites like BBC, CNN etc.</p>
<div id="toc">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#why-scraping">Why Scraping?</a></li>
    <li><a href="#scraping-with-python">Scraping with Python</a></li>
    <li><a href="#challenges-while-scraping">Challenges while scraping</a></li>
    <li><a href="#python-packages-for-scraping">Python packages for scraping</a></li>
    <li><a href="#scraping-approach">Scraping approach</a></li>
    <li><a href="#using-proxies-for-ip-rotation">Using proxies for IP rotation</a></li>
    <li><a href="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</div>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-0206245742790279"
     data-ad-slot="3890452391"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2 id="why-scraping">Why Scraping?</h2>
<p>There are millions of websites on the Internet which have information on different topics. For example, news, travel, food, finance, business, tech, entertainment, to name a few. All these websites don&rsquo;t have a proper way (APIs or feeds) of sharing data. So, we need scrape such websites to extract the information.</p>
<p>Scrapers parse the HTML elements of the page using tags, ids, class names etc to get the required content from the page. Consider the following simple HTML page:</p>
<script type="application/javascript" src="https://gist.github.com/saisyam/9d13a4e0c16de8326b491bd89a77c963.js"></script>

<p>The above HTML snippet contains tags like, <code>title</code>, <code>div</code>, <code>h1</code>, and <code>p</code>. We can extract the <code>div</code> element with <code>id=main</code> and then extract text between <code>h1</code> and <code>p</code> tags under the <code>div</code> element. We can identify specific tags using <code>id</code> or <code>class</code> or any other attributes.</p>
<h2 id="scraping-with-python">Scraping with Python</h2>
<p>It&rsquo;s easy to write scrapers in Python. Python has a rich set of tools or packages to perform scraping effectively. The below code snippet parses the above HTML and extracts the information required:</p>
<script type="application/javascript" src="https://gist.github.com/saisyam/7d19d9c6247194e9130e578e08be6336.js"></script>

<p>The above code uses <code>Beautifulsoup</code> package. The response of the above function is:</p>
<script type="application/javascript" src="https://gist.github.com/saisyam/e62bc0ff7ce7a817034140ed667017c9.js"></script>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-0206245742790279"
     data-ad-slot="3890452391"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2 id="challenges-while-scraping">Challenges while scraping</h2>
<p>Not all web pages are so simple as shown in the above example. Below is the list of challenges that we encounter while scraping:</p>
<ol>
<li><strong>Dynamic content</strong> - Today most of the websites use latest JavaScript frameworks to build their sites. The content or the HTML that is rendered is generated dynamically with JavaScript. You need a real browser to load the webpage inorder to get the rendered HTML</li>
<li><strong>Getting blocked</strong> - Websites will block your IP address if they see a continuous traffic from you. While developing the scraper you will continuously hit their website which makes the website think of a suspicious activity and block your IP. If possible download the static HTML page and build your scraper. Most scrapers use proxy IP addresses to solve this problem.</li>
<li><strong>Captcha</strong> - Most websites will check whether you are a human or not when they detect a suspicious activity as mentioned in point <strong>#2</strong>. Always try to avoid this situation. Though there are captcha solving tools, they are not 100% reliable or accurate.</li>
</ol>
<h2 id="python-packages-for-scraping">Python packages for scraping</h2>
<p>In order to parse HTML, first we need to get the HTML of the page. There are two ways in Python to get the HTML content of the page:</p>
<ol>
<li><strong>Using <code>requests</code> package</strong> - <a href="https://requests.readthedocs.io/en/master/">Requests</a> is a Python package, HTTP library built for humans. We use <code>requests.get()</code> method to get the HTML content of a page. The advantage of this is, it is fast and simple but will not get the dynamically loaded content as it is not a browser to execute JavaScript.</li>
<li><strong>Using <code>splinter</code> package</strong> - <a href="https://splinter.readthedocs.io/en/latest/">Splinter</a> is a Python package used to test web applications. Splinter uses webdrivers (Chrome, Firefox etc) to load a web page and get HTML. You need to have browser application and associated webdriver to make it work. With Splinter we can get dynamically loaded content as well.</li>
</ol>
<h2 id="scraping-approach">Scraping approach</h2>
<p>The approach that we follow for creating scrapers are:</p>
<ol>
<li>Get HTML content of the website using <code>requests</code> or <code>splinter</code> based on the requirement.</li>
<li>Use <code>Beautifulsoup</code> to parse the HTML and extract the content. <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> is a Python package used to parse HTML content. <code>Beautifulsoup</code> supports multiple HTML parsers. <code>html5lib</code> is a parser built completely in Python and considered as the fastest among the existing parsers.</li>
</ol>
<p>Getting the complete HTML content is a complex activity, because of the challenges explained in the above section. We avoid using single IP address and use proxies and rotate our IPs. There are some free proxy providers like <a href="https://sslproxies.org/">SSLProxy</a>, <a href="https://spys.one/en/https-ssl-proxy/">SpysOne</a>, <a href="https://www.proxy-list.download/HTTPS">ProxyList</a> to name a few.</p>
<p>If you don&rsquo;t want to deal with all the mess and do just parsing the content, use <a href="https://www.scraperapi.com/">ScraperAPI</a>. It is a proxy API for web scraping. Scraper API handles proxies, browsers, and CAPTCHAs, so you can get the HTML from any web page with a simple API call!. Check out <a href="https://www.scrapingbee.com/">ScrapingBee</a> as well.</p>
<h2 id="using-proxies-for-ip-rotation">Using proxies for IP rotation</h2>
<p>You can tell <code>requests</code> API to use proxies to fetch html.</p>
<script type="application/javascript" src="https://gist.github.com/saisyam/12410ff3c8c027cf0b58c903bff0d5a8.js"></script>

<p>Your request will go through the proxy address provided. Use HTTP proxies to skip SSL verification step which happens in case of HTTPS proxies.</p>
<p>In a similar way, we can use proxies with Splinter as well. We use Chrome browser here.</p>
<script type="application/javascript" src="https://gist.github.com/saisyam/7b8b7f4954086ae581a59b31731ec38f.js"></script>

<p>If one IP gets blocked, you can get an another one and continue scraping.</p>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-0206245742790279"
     data-ad-slot="3890452391"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h2 id="conclusion">Conclusion</h2>
<p>In this article we learnt what is scraping and why it is required. We have explored few packages in Python to do scraping and identified challenges in scraping along with few solutions to overcome those challenges. For more information on scraping visit my <a href="https://github.com/saisyam/scrapers">Scrapers</a> repository on Github. Happy scraping!</p>

                </p>
            </div>
            <a class="tag" href="https://saisyam.com/tags/beautifulsoup/">#BeautifulSoup</a>
            <a class="tag" href="https://saisyam.com/tags/proxies/">#Proxies</a>
            <a class="tag" href="https://saisyam.com/tags/requests/">#Requests</a>
            <a class="tag" href="https://saisyam.com/tags/splinter/">#Splinter</a>
            <a class="tag" href="https://saisyam.com/tags/web-scraping/">#Web Scraping</a>
            <a class="tag" href="https://saisyam.com/tags/webdriver/">#Webdriver</a>
            
        </section>
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "saisyam-1" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      </div>
      <div class="footer">
  <div class="pure-menu pure-menu-horizontal">
      <ul>
          <li class="pure-menu-item"><a href="https://saisyam.com/about" class="pure-menu-link">About</a></li>
          <li class="pure-menu-item"><a href="https://in.linkedin.com/in/saisyam" class="pure-menu-link">LinkedIn</a></li>
          <li class="pure-menu-item"><a href="https://github.com/saisyam" class="pure-menu-link">GitHub</a></li>
      </ul>
  </div>
</div>


  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-50423294-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



    </div>
  </div>
<script type="application/ld+json">
    
    {
      "@context": "https://schema.org",
      "@type": "BlogPosting",
      "headline": "Effective Web Scraping with Python",
      "image": "https://saisyam.com/",
      "datePublished": "2021-01-10T00:00:00Z",
      "dateModified": "2021-01-10T00:00:00Z",
      "author": {
        "@type": "Person",
        "name":  null 
      },
      "mainEntityOfPage": { "@type": "WebPage" },
       "publisher": {
        "@type": "Organization",
        "name":  null ,
        "logo": {
          "@type": "ImageObject",
          "url":  null 
        }
      },
      "description": "Web scraping is a process of automatically extracting information from websites. Web scrapers are small programs written to crawl and extract specific information from a webpage. For example, getting latest news items from news websites like BBC, CNN etc.",
      "keywords": ["Web Scraping", "Splinter", "BeautifulSoup", "Requests", "Proxies", "Webdriver"]
    }
    
    {
      "@context": "https://schema.org",
      "@type": "Organization",
      "name": "Personal blog",
      "url": "https://saisyam.com/",
      "sameAs": [
        "https://www.facebook.com/saisyam.dampuri.5667",
        "https://www.instagram.com/saisyamdampuri",
        "https://twitter.com/saisyam1",
        "https://github.com/saisyam"
      ]
    }
    </script>

    </div>
</body>
</html>

