
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
 <channel>
   <title>Generative Adversarial Networks on Saisyam</title>
   <link>https://saisyam.com/tags/generative-adversarial-networks/</link>
   <description>Recent content in Generative Adversarial Networks on Saisyam</description>
   <generator>Hugo -- gohugo.io</generator>
   <copyright>Copyright &amp;copy; 2020 - Saisyam</copyright>
   <lastBuildDate>Tue, 08 Aug 2023 00:00:00 +0000</lastBuildDate>
   
       <atom:link href="https://saisyam.com/tags/generative-adversarial-networks/index.xml" rel="self" type="application/rss+xml" />
   
   
     <item>
       <title>Simplify Data Engineering with Docker: A Guide to Using Containers for Data Tools</title>
       <link>https://saisyam.com/simplify-data-engineering-with-docker-a-guide-to-using-containers-for-data-tools/</link>
       <pubDate>Sun, 10 Sep 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/simplify-data-engineering-with-docker-a-guide-to-using-containers-for-data-tools/</guid>
       <description>&lt;p&gt;In the world of data engineering, managing different data tools and dependencies for various projects can be a daunting task. Installation, configuration, and version mismatches can lead to a headache. But fear not! Docker containers come to the rescue, offering an elegant solution that saves you from the hassle of traditional installations.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#what-is-docker&#34;&gt;What is Docker?&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#why-docker&#34;&gt;Why Docker?&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#installing-docker-on-windows-linux-and-mac&#34;&gt;Installing Docker on Windows, Linux, and Mac&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#using-docker-images-for-data-tools&#34;&gt;Using Docker Images for Data Tools&lt;/a&gt;      &lt;ul&gt;        &lt;li&gt;&lt;a href=&#34;#step-1-pull-docker-images&#34;&gt;Step 1: Pull Docker Images&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#step-2-running-downloaded-images&#34;&gt;Step 2: Running downloaded images&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#step-3-connecting-to-these-containers-from-python&#34;&gt;Step 3: Connecting to these containers from Python&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#step-4-managing-data-in-docker-containers&#34;&gt;Step 4: Managing Data in Docker Containers&lt;/a&gt;&lt;/li&gt;      &lt;/ul&gt;    &lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;what-is-docker&#34;&gt;What is Docker?&lt;/h2&gt;&lt;p&gt;&lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt; is an open-source platform that automates application deployment and management by containerizing them. Containers are lightweight, standalone, and executable packages that include everything needed to run a piece of software, including the code, runtime, libraries, and system tools.&lt;/p&gt;&lt;p&gt;With Docker, data engineers can isolate data tools and other software, ensuring consistency across development, testing, and production environments. Here&amp;rsquo;s a brief overview of Docker&amp;rsquo;s key components:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Docker Engine:&lt;/strong&gt; The core component that allows you to create and run containers.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Dockerfile:&lt;/strong&gt; A script that defines how a container should be built.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Docker Compose:&lt;/strong&gt; A tool for defining and running multi-container Docker applications&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&#34;why-docker&#34;&gt;Why Docker?&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Development Ease&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Docker simplifies the development process by encapsulating applications and their dependencies into containers. Developers can create a consistent environment locally, ensuring that the same set of tools and libraries are used across different development stages. This consistency minimizes the &amp;ldquo;it works on my machine&amp;rdquo; problem and streamlines collaboration.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Portability&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One of Docker&amp;rsquo;s key advantages is portability. Containers can run consistently across various environments, including local development machines, testing servers, and production clusters. This portability allows you to build and test applications locally and then deploy them seamlessly to cloud platforms like AWS Elastic Container Service (ECS) or Kubernetes.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;When working with large datasets or demanding data processing tasks, Docker containers can be effortlessly scaled up or down to meet your performance requirements. Cloud orchestration services like Kubernetes and AWS ECS excel at managing containerized applications, automatically adjusting the number of containers as needed.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Cloud Deployment&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Docker containers are the de facto standard for deploying applications in cloud environments. Cloud providers offer container orchestration platforms like AWS Elastic Kubernetes Service (EKS) and Azure Kubernetes Service (AKS) that make it straightforward to manage and scale containers on the cloud.&lt;/p&gt;&lt;p&gt;By adopting Docker early in your data engineering journey, you set yourself up for success when it comes to deploying your data applications in cloud environments.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;installing-docker-on-windows-linux-and-mac&#34;&gt;Installing Docker on Windows, Linux, and Mac&lt;/h2&gt;&lt;p&gt;Before you can start using Docker for your data engineering projects, you&amp;rsquo;ll need to install Docker on your operating system. Docker provides installation guides for Windows, Linux, and Mac, so you can choose the instructions that match your setup.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Windows Installation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For detailed installation instructions on Windows, please visit the official Docker installation guide for Windows: &lt;a href=&#34;https://www.docker.com/products/docker-desktop/&#34;&gt;Docker Desktop for Windows&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Linux Installation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For detailed installation instructions on Linux, please visit the official Docker installation guide for Linux: &lt;a href=&#34;https://docs.docker.com/install/linux-install/&#34;&gt;Docker for Linux&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Mac Installation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For detailed installation instructions on macOS, please visit the official Docker installation guide for Mac: &lt;a href=&#34;https://www.docker.com/products/docker-desktop&#34;&gt;Docker Desktop for Mac&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Once you&amp;rsquo;ve installed Docker according to your operating system, you can proceed with the steps mentioned in the previous sections to work with Docker containers effectively.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;using-docker-images-for-data-tools&#34;&gt;Using Docker Images for Data Tools&lt;/h2&gt;&lt;p&gt;Using Docker images for data engineering tools is a game-changer for data engineers. Instead of manual installations, you can simply pull pre-configured tool images from Docker Hub, a repository of Docker images. I use these images frequently to test data pipeline concepts using Kafka, Apache Flink and databases. Let&amp;rsquo;s see how it&amp;rsquo;s done:&lt;/p&gt;&lt;h3 id=&#34;step-1-pull-docker-images&#34;&gt;Step 1: Pull Docker Images&lt;/h3&gt;&lt;p&gt;Use the docker pull command to fetch the desired data tool images. For example, to get Bitnami Kafka:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;docker pull bitnami/kafka&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And for PostgreSQL:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;docker pull postgres&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These commands download the official images from Docker Hub.&lt;/p&gt;&lt;h3 id=&#34;step-2-running-downloaded-images&#34;&gt;Step 2: Running downloaded images&lt;/h3&gt;&lt;p&gt;Once you&amp;rsquo;ve pulled the images, it&amp;rsquo;s time to spin up containers for your data tools. Here&amp;rsquo;s how to do it:Bitnami Kafka Container&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;docker run --name my-kafka -d bitnami/kafka&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;PostgreSQL Container&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;docker run --name my-postgres -e POSTGRES_PASSWORD&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mysecretpassword -d -p 5432:5432 postgres&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You now have Bitnami Kafka and PostgreSQL running in Docker containers!&lt;/p&gt;&lt;h3 id=&#34;step-3-connecting-to-these-containers-from-python&#34;&gt;Step 3: Connecting to these containers from Python&lt;/h3&gt;&lt;p&gt;Python makes it easy to connect to data tools within Docker containers. Here are code snippets for Kafka and PostgreSQL:Kafka Connection&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Import the Kafka Python library&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; kafka &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; KafkaProducer, KafkaConsumer&lt;span style=&#34;color:#75715e&#34;&gt;# Create a Kafka producer&lt;/span&gt;producer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; KafkaProducer(bootstrap_servers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;my-kafka:9092&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#75715e&#34;&gt;# Create a Kafka consumer&lt;/span&gt;consumer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; KafkaConsumer(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;my-topic&amp;#39;&lt;/span&gt;, bootstrap_servers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;my-kafka:9092&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#75715e&#34;&gt;# You can send and receive messages using &amp;#39;producer&amp;#39; and &amp;#39;consumer&amp;#39;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;PostgreSQL Connection&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; psycopg2conn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; psycopg2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;connect(    host&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;,    port&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;5432&amp;#34;&lt;/span&gt;,    database&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;postgres&amp;#34;&lt;/span&gt;,    user&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;postgres&amp;#34;&lt;/span&gt;,    password&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mysecretpassword&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#75715e&#34;&gt;# Now you can execute SQL queries using &amp;#39;conn&amp;#39;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These code snippets establish connections to Kafka and PostgreSQL within Docker containers, allowing you to work with data seamlessly.&lt;/p&gt;&lt;h3 id=&#34;step-4-managing-data-in-docker-containers&#34;&gt;Step 4: Managing Data in Docker Containers&lt;/h3&gt;&lt;p&gt;To ensure data persistence in Docker containers, consider using Docker volumes. Volumes allow you to store data outside the container, making it easier to manage. You can back up and restore data easily by working with volumes.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Docker simplifies data engineering tasks by providing a consistent and reproducible environment for managing data tools like Kafka and PostgreSQL. With just a few commands, you can have your data tools up and running in containers. Python makes it a breeze to connect and work with the data. Embrace Docker, and say goodbye to installation and configuration woes in your data engineering journey!&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Demystifying Generative AI: Exploring the Fundamentals and Applications</title>
       <link>https://saisyam.com/demystifying-generative-ai-exploring-the-fundamentals-and-applications/</link>
       <pubDate>Tue, 08 Aug 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/demystifying-generative-ai-exploring-the-fundamentals-and-applications/</guid>
       <description>&lt;p&gt;In the rapidly evolving landscape of artificial intelligence, one intriguing realm that has captured the imagination of researchers, developers, and enthusiasts alike is Generative AI. This innovative field is at the forefront of creativity, enabling machines to generate content that ranges from images and text to music and more.&lt;/p&gt;&lt;p&gt;In this article, we&amp;rsquo;ll take a deep dive into the foundational concepts of Generative AI, exploring key techniques such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Autoregressive Models. Along the way, we&amp;rsquo;ll uncover the real-world applications that make this field so impactful, and we&amp;rsquo;ll even provide you with hands-on code examples to kickstart your own creative AI journey.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#understanding-generative-ai-a-brief-overview&#34;&gt;Understanding Generative AI: A Brief Overview&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#the-power-of-gans-generative-adversarial-networks&#34;&gt;The Power of GANs (Generative Adversarial Networks)&lt;/a&gt;      &lt;ul&gt;        &lt;li&gt;&lt;a href=&#34;#real-world-applications-of-gans&#34;&gt;Real-World Applications of GANs&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#code-example-creating-a-gan&#34;&gt;Code Example: Creating a GAN&lt;/a&gt;&lt;/li&gt;      &lt;/ul&gt;    &lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#exploring-vaes-variational-autoencoders&#34;&gt;Exploring VAEs (Variational Autoencoders)&lt;/a&gt;      &lt;ul&gt;        &lt;li&gt;&lt;a href=&#34;#real-world-applications-of-vaes&#34;&gt;Real-World Applications of VAEs&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#code-example-building-a-vae&#34;&gt;Code Example: Building a VAE&lt;/a&gt;&lt;/li&gt;      &lt;/ul&gt;    &lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#unveiling-autoregressive-models&#34;&gt;Unveiling Autoregressive Models&lt;/a&gt;      &lt;ul&gt;        &lt;li&gt;&lt;a href=&#34;#real-world-applications-of-autoregressive-models&#34;&gt;Real-World Applications of Autoregressive Models&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#code-example-constructing-an-autoregressive-model&#34;&gt;Code Example: Constructing an Autoregressive Model&lt;/a&gt;&lt;/li&gt;      &lt;/ul&gt;    &lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#embarking-on-your-generative-ai-journey&#34;&gt;Embarking on Your Generative AI Journey&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;understanding-generative-ai-a-brief-overview&#34;&gt;Understanding Generative AI: A Brief Overview&lt;/h2&gt;&lt;p&gt;At its core, Generative AI is all about teaching machines to create new and original content. This is a stark departure from traditional AI systems that focus on tasks like classification and prediction. Generative AI empowers machines to unleash their creative potential, opening doors to applications that were once deemed the exclusive domain of human creativity.&lt;/p&gt;&lt;h2 id=&#34;the-power-of-gans-generative-adversarial-networks&#34;&gt;The Power of GANs (Generative Adversarial Networks)&lt;/h2&gt;&lt;p&gt;Generative Adversarial Networks, or GANs, stand as one of the most influential developments in Generative AI. The concept behind GANs is both elegant and intuitive: pitting two neural networks, the generator and the discriminator, against each other in a game-like framework. The generator&amp;rsquo;s objective is to produce content that closely resembles real data, while the discriminator&amp;rsquo;s task is to differentiate between genuine data and the generated output. Through a process of continuous iteration, the generator becomes increasingly skilled at creating content that is nearly indistinguishable from reality.&lt;/p&gt;&lt;h3 id=&#34;real-world-applications-of-gans&#34;&gt;Real-World Applications of GANs&lt;/h3&gt;&lt;p&gt;The applications of GANs span diverse domains, showcasing their versatility and potential impact. In the realm of image synthesis, GANs have been employed to create breathtakingly realistic visuals, enabling artists and designers to bring their visions to life. Style transfer, where the characteristics of one image are applied to another, has also seen tremendous advancements thanks to GANs. Additionally, industries such as gaming have leveraged GANs to fabricate lifelike characters and immersive environments that blur the line between the virtual and the real.&lt;/p&gt;&lt;h3 id=&#34;code-example-creating-a-gan&#34;&gt;Code Example: Creating a GAN&lt;/h3&gt;&lt;p&gt;Implement a simple GAN using Python and TensorFlow, training it on a dataset of handwritten digits to generate realistic-looking numbers.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Sample GAN code snippet&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# (Note: This is a simplified example; actual GANs are more complex.)&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Generator model&lt;/span&gt;generator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Sequential([&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;])&lt;span style=&#34;color:#75715e&#34;&gt;# Discriminator model&lt;/span&gt;discriminator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Sequential([&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;])&lt;span style=&#34;color:#75715e&#34;&gt;# Combined GAN model&lt;/span&gt;gan &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Sequential([generator, discriminator])&lt;span style=&#34;color:#75715e&#34;&gt;# Training loop&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_epochs):    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; real_images &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dataset:        &lt;span style=&#34;color:#75715e&#34;&gt;# Train discriminator on real images&lt;/span&gt;        d_loss_real &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; discriminator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train_on_batch(real_images, real_labels)                &lt;span style=&#34;color:#75715e&#34;&gt;# Generate fake images&lt;/span&gt;        fake_images &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; generator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(noise)                &lt;span style=&#34;color:#75715e&#34;&gt;# Train discriminator on fake images&lt;/span&gt;        d_loss_fake &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; discriminator&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train_on_batch(fake_images, fake_labels)                &lt;span style=&#34;color:#75715e&#34;&gt;# Train generator to fool discriminator&lt;/span&gt;        g_loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gan&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train_on_batch(noise, real_labels)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;exploring-vaes-variational-autoencoders&#34;&gt;Exploring VAEs (Variational Autoencoders)&lt;/h2&gt;&lt;p&gt;Variational Autoencoders, or VAEs, offer another avenue into the world of Generative AI. VAEs are a type of autoencoder, a neural network architecture designed for data compression and feature extraction. What sets VAEs apart is their incorporation of probabilistic latent variables. These variables allow for the generation of diverse outputs from a single encoded representation, adding a touch of randomness and creativity to the process.&lt;/p&gt;&lt;h3 id=&#34;real-world-applications-of-vaes&#34;&gt;Real-World Applications of VAEs&lt;/h3&gt;&lt;p&gt;VAEs shine in applications such as image generation and data compression. They have been employed to generate realistic images, perform data denoising, and even aid in anomaly detection by identifying deviations from expected patterns.&lt;/p&gt;&lt;h3 id=&#34;code-example-building-a-vae&#34;&gt;Code Example: Building a VAE&lt;/h3&gt;&lt;p&gt;Build a simple VAE using PyTorch, training it on a dataset of grayscale images to generate new images with similar features.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Sample VAE code snippet&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# (Note: This is a simplified example; actual VAEs are more complex.)&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define VAE model&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;VAE&lt;/span&gt;(nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module):    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self):        super(VAE, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__()        [&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]            &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt;(self, x):        [&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]            &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt;(self, z):        [&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]&lt;span style=&#34;color:#75715e&#34;&gt;# Loss function (combination of reconstruction loss and KL divergence)&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss_function&lt;/span&gt;(recon_x, x, mu, logvar):    [&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]&lt;span style=&#34;color:#75715e&#34;&gt;# Training loop&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_epochs):    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; batch_idx, (data, _) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(dataloader):        [&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]&lt;span style=&#34;color:#75715e&#34;&gt;# Generate new images&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;no_grad():    sample &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, latent_dim)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to(device)    sample &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(sample)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;unveiling-autoregressive-models&#34;&gt;Unveiling Autoregressive Models&lt;/h2&gt;&lt;p&gt;Autoregressive Models present a distinct approach to Generative AI. Unlike GANs and VAEs, which operate on a global scale, autoregressive models generate content sequentially, element by element. Each element&amp;rsquo;s generation is influenced by the preceding elements, resulting in coherent and structured outputs.&lt;/p&gt;&lt;h3 id=&#34;real-world-applications-of-autoregressive-models&#34;&gt;Real-World Applications of Autoregressive Models&lt;/h3&gt;&lt;p&gt;Autoregressive models have found their niche in text generation, handwriting synthesis, and speech synthesis. They excel in scenarios where the order and context of generated content are crucial.&lt;/p&gt;&lt;h3 id=&#34;code-example-constructing-an-autoregressive-model&#34;&gt;Code Example: Constructing an Autoregressive Model&lt;/h3&gt;&lt;p&gt;Implement a basic autoregressive language model using TensorFlow, training it on a text dataset to generate new paragraphs of text.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Sample autoregressive model code snippet&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# (Note: This is a simplified example; actual models are more complex.)&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define autoregressive model&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;AutoregressiveModel&lt;/span&gt;(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model):    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self):        super(AutoregressiveModel, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__()        [&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]            &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;call&lt;/span&gt;(self, inputs, training&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;):        [&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;]        &lt;span style=&#34;color:#75715e&#34;&gt;# Loss function (cross-entropy)&lt;/span&gt;loss_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;losses&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SparseCategoricalCrossentropy(from_logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&lt;span style=&#34;color:#75715e&#34;&gt;# Training loop&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_epochs):    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; batch &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dataset:        &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:            predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(inputs, training&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)            loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; loss_fn(labels, predictions)        gradients &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable_variables)        optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients(zip(gradients, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable_variables))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;embarking-on-your-generative-ai-journey&#34;&gt;Embarking on Your Generative AI Journey&lt;/h2&gt;&lt;p&gt;Generative AI is more than just a technological advancement; it&amp;rsquo;s a doorway to creativity that blurs the boundaries between man and machine. The techniques we&amp;rsquo;ve explored – GANs, VAEs, and autoregressive models – are driving the evolution of AI-driven creativity across various domains. Whether you&amp;rsquo;re an artist seeking to collaborate with algorithms or a developer aspiring to craft novel solutions, Generative AI has something to offer.&lt;/p&gt;&lt;p&gt;As you&amp;rsquo;ve seen from the code examples provided (high level boilerplates, will explore in-depth in future articles), experimenting with Generative AI need not be a daunting task. These snippets serve as stepping stones, guiding you toward harnessing the potential of AI to create content that challenges convention and sparks inspiration.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In this age of digital transformation, Generative AI stands as a testament to the incredible feats that can be achieved when technology and creativity converge. By embracing the fundamentals and applications of Generative AI, you embark on a journey that not only demystifies the inner workings of AI but also empowers you to explore uncharted territories of innovation and imagination. So, what will you create next? The possibilities are limited only by your imagination.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Introduction to Data Analysis with Python: A Beginner&#39;s Guide</title>
       <link>https://saisyam.com/introduction-to-data-analysis-with-python-a-beginners-guide/</link>
       <pubDate>Mon, 07 Aug 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/introduction-to-data-analysis-with-python-a-beginners-guide/</guid>
       <description>&lt;p&gt;Data analysis has become an integral part of numerous industries, driving critical decision-making processes and uncovering valuable insights. Python, a versatile and powerful programming language, has emerged as a popular choice for data analysis due to its ease of use and a rich ecosystem of libraries tailored for this purpose. In this beginner&amp;rsquo;s guide, we will explore the fundamentals of data analysis using Python, covering essential concepts and key libraries that will equip you to embark on your data exploration journey.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#why-python-for-data-analysis&#34;&gt;Why Python for Data Analysis?&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#setting-up-your-data-analysis-environment&#34;&gt;Setting Up Your Data Analysis Environment&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#getting-started-with-numpy&#34;&gt;Getting Started with NumPy&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#data-wrangling-with-pandas&#34;&gt;Data Wrangling with Pandas&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#exploring-and-visualizing-data-with-matplotlib&#34;&gt;Exploring and Visualizing Data with Matplotlib&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#common-techniques-and-tools&#34;&gt;Common Techniques and Tools&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;why-python-for-data-analysis&#34;&gt;Why Python for Data Analysis?&lt;/h2&gt;&lt;p&gt;Python has gained immense popularity in the data science community for several reasons. Firstly, it boasts a user-friendly syntax that facilitates readability and reduces the learning curve for beginners. Secondly, Python&amp;rsquo;s open-source nature fosters a vibrant community, leading to a vast array of libraries dedicated to data analysis, such as &lt;a href=&#34;https://numpy.org/&#34;&gt;NumPy&lt;/a&gt;, &lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;Pandas&lt;/a&gt;, and &lt;a href=&#34;https://matplotlib.org/&#34;&gt;Matplotlib&lt;/a&gt;. Lastly, Python&amp;rsquo;s versatility enables seamless integration with other domains like web development and machine learning.&lt;/p&gt;&lt;h2 id=&#34;setting-up-your-data-analysis-environment&#34;&gt;Setting Up Your Data Analysis Environment&lt;/h2&gt;&lt;p&gt;Before diving into data analysis, you need to set up your Python environment. We&amp;rsquo;ll walk you through the process of installing Python, managing packages with pip, and introducing Jupyter Notebook—a popular interactive environment for data analysis. Refer to this article on &lt;a href=&#34;https://saisyam.com/setting-up-a-python-data-environment-a-comprehensive-guide-for-data-enthusiasts/&#34;&gt;how to setup your Python virtual environment for data processing&lt;/a&gt;.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;getting-started-with-numpy&#34;&gt;Getting Started with NumPy&lt;/h2&gt;&lt;p&gt;&lt;a href=&#34;https://numpy.org/&#34;&gt;NumPy&lt;/a&gt; is a library for working with arrays of data. It provides a wide range of functions for performing mathematical operations on arrays, as well as tools for working with matrices and linear algebra. NumPy is often used as the foundation for other data analysis libraries in Python.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ pip install numpy&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;data-wrangling-with-pandas&#34;&gt;Data Wrangling with Pandas&lt;/h2&gt;&lt;p&gt;&lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;Pandas&lt;/a&gt; is a library for working with structured data. It provides powerful tools for reading, writing, and manipulating data in various formats, including CSV, Excel, and SQL databases. Pandas also includes many useful functions for cleaning and transforming data, making it an essential tool for any data analyst.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ pip install pandas&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;exploring-and-visualizing-data-with-matplotlib&#34;&gt;Exploring and Visualizing Data with Matplotlib&lt;/h2&gt;&lt;p&gt;&lt;a href=&#34;https://matplotlib.org/&#34;&gt;Matplotlib&lt;/a&gt; is a library for creating visualizations in Python. It provides a wide range of tools for creating plots, charts, and graphs, allowing you to easily explore and communicate your data. Matplotlib is highly customizable and can be used to create complex visualizations with just a few lines of code.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ pip install matplotlib&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;common-techniques-and-tools&#34;&gt;Common Techniques and Tools&lt;/h2&gt;&lt;p&gt;In addition to the libraries mentioned above, there are many other techniques and tools commonly used in data analysis with Python. Some of these include:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Data cleaning:&lt;/strong&gt; Preparing your data for analysis by removing or correcting errors, filling in missing values, and transforming variables.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Exploratory data analysis:&lt;/strong&gt; Exploring your data through visualizations and summary statistics to gain insights and identify patterns.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Statistical modeling:&lt;/strong&gt; Building models to describe the relationships between variables in your data.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Machine learning:&lt;/strong&gt; Using algorithms to make predictions or classify observations based on your data.&lt;/li&gt;&lt;/ol&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Python is an excellent choice for beginners looking to get started with data analysis. With its easy-to-learn syntax, extensive libraries, and active community, there are many resources available to help you learn and grow as a data analyst. We hope this introduction has provided you with a solid foundation to start exploring the world of data analysis with Python!&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Setting Up a Python Data Environment: A Comprehensive Guide for Data Enthusiasts</title>
       <link>https://saisyam.com/setting-up-a-python-data-environment-a-comprehensive-guide-for-data-enthusiasts/</link>
       <pubDate>Thu, 03 Aug 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/setting-up-a-python-data-environment-a-comprehensive-guide-for-data-enthusiasts/</guid>
       <description>&lt;p&gt;Setting up a Python data environment is the first crucial step for data enthusiasts, data scientists, and analysts embarking on their data-driven journey. Python has become the go-to language for data analysis due to its versatility, rich libraries, and ease of use. In this blog post, we will provide a comprehensive guide to help you set up a robust Python data environment, ensuring you have all the essential tools and libraries at your disposal.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#why-python-for-data-analysis&#34;&gt;Why Python for Data Analysis?&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#setting-up-your-python-data-environment&#34;&gt;Setting Up Your Python Data Environment&lt;/a&gt;      &lt;ul&gt;        &lt;li&gt;&lt;a href=&#34;#step-1-install-python&#34;&gt;Step 1: Install Python&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#step-2-package-manager---pip&#34;&gt;Step 2: Package Manager - Pip&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#step-3-virtual-environments&#34;&gt;Step 3: Virtual Environments&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#step-4-essential-libraries-for-data-analysis&#34;&gt;Step 4: Essential Libraries for Data Analysis&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#step-5-integrated-development-environment-ide&#34;&gt;Step 5: Integrated Development Environment (IDE)&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#step-6-jupyter-notebook&#34;&gt;Step 6: Jupyter Notebook&lt;/a&gt;&lt;/li&gt;        &lt;li&gt;&lt;a href=&#34;#step-7-additional-libraries-based-on-your-needs&#34;&gt;Step 7: Additional Libraries (Based on Your Needs)&lt;/a&gt;&lt;/li&gt;      &lt;/ul&gt;    &lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;why-python-for-data-analysis&#34;&gt;Why Python for Data Analysis?&lt;/h2&gt;&lt;p&gt;Before we dive into the setup process, let&amp;rsquo;s quickly explore why Python is the preferred choice for data analysis:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Versatility:&lt;/strong&gt; Python is a versatile language that can handle a wide range of tasks, from data manipulation and analysis to machine learning and web development.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Large Ecosystem:&lt;/strong&gt; Python boasts a vast ecosystem of libraries and frameworks specifically designed for data-related tasks, such as Pandas, NumPy, Matplotlib, Seaborn, and more.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Easy to Learn:&lt;/strong&gt; Python&amp;rsquo;s simple and readable syntax makes it accessible to beginners and experienced programmers alike, reducing the learning curve.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Community Support:&lt;/strong&gt; Python has a large and active community that continuously contributes to its development, providing resources, tutorials, and assistance.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;setting-up-your-python-data-environment&#34;&gt;Setting Up Your Python Data Environment&lt;/h2&gt;&lt;p&gt;Now, let&amp;rsquo;s walk through the step-by-step process of setting up your Python data environment:&lt;/p&gt;&lt;h3 id=&#34;step-1-install-python&#34;&gt;Step 1: Install Python&lt;/h3&gt;&lt;p&gt;The first step is to install Python on your system. Visit the official &lt;a href=&#34;https://www.python.org/&#34;&gt;Python website&lt;/a&gt; and download the latest version compatible with your operating system (Windows, macOS, or Linux). During the installation, make sure to check the box that adds Python to your system&amp;rsquo;s PATH to access it from the command line.&lt;/p&gt;&lt;h3 id=&#34;step-2-package-manager---pip&#34;&gt;Step 2: Package Manager - Pip&lt;/h3&gt;&lt;p&gt;Pip is Python&amp;rsquo;s default package manager used to install and manage Python libraries. It comes pre-installed with Python versions 2.7.9 and later. To check if you have pip installed, open the command prompt (or terminal for macOS/Linux) and type:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;pip --version&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h3 id=&#34;step-3-virtual-environments&#34;&gt;Step 3: Virtual Environments&lt;/h3&gt;&lt;p&gt;Virtual environments allow you to create isolated Python environments for different projects, ensuring dependencies do not interfere with each other. While optional, using virtual environments is highly recommended to maintain a clean and organized development environment. To create a virtual environment, run the following commands:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Install virtualenv package (if not already installed)&lt;/span&gt;pip install virtualenv&lt;span style=&#34;color:#75715e&#34;&gt;# Create a new virtual environment&lt;/span&gt;virtualenv myenv&lt;span style=&#34;color:#75715e&#34;&gt;# Activate the virtual environment (Windows)&lt;/span&gt;myenv&lt;span style=&#34;color:#ae81ff&#34;&gt;\S&lt;/span&gt;cripts&lt;span style=&#34;color:#ae81ff&#34;&gt;\a&lt;/span&gt;ctivate&lt;span style=&#34;color:#75715e&#34;&gt;# Activate the virtual environment (macOS/Linux)&lt;/span&gt;source myenv/bin/activate&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h3 id=&#34;step-4-essential-libraries-for-data-analysis&#34;&gt;Step 4: Essential Libraries for Data Analysis&lt;/h3&gt;&lt;p&gt;To perform data analysis in Python, you&amp;rsquo;ll need some essential libraries. Let&amp;rsquo;s install them using pip:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;pip install pandas numpy matplotlib seaborn&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Pandas:&lt;/strong&gt; A powerful library for data manipulation and analysis, providing data structures like DataFrames and Series.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;NumPy:&lt;/strong&gt; A fundamental package for numerical computing with support for arrays and matrices.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Matplotlib:&lt;/strong&gt; A widely used library for creating static, interactive, and animated visualizations.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Seaborn:&lt;/strong&gt; A data visualization library based on Matplotlib, offering a higher-level interface for creating informative statistical graphics.&lt;/li&gt;&lt;/ol&gt;&lt;h3 id=&#34;step-5-integrated-development-environment-ide&#34;&gt;Step 5: Integrated Development Environment (IDE)&lt;/h3&gt;&lt;p&gt;While Python code can be written using a simple text editor, using an Integrated Development Environment (IDE) enhances productivity. There are several popular IDEs available for Python:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;PyCharm:&lt;/strong&gt; A powerful and feature-rich IDE developed by JetBrains, offering community and professional editions.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Visual Studio Code (VSCode):&lt;/strong&gt; A lightweight, customizable IDE with strong Python support through extensions.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Spyder:&lt;/strong&gt; An IDE designed specifically for scientific computing and data analysis, providing an interface similar to MATLAB.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;I use Visual Studio Code (VSCode).&lt;/p&gt;&lt;h3 id=&#34;step-6-jupyter-notebook&#34;&gt;Step 6: Jupyter Notebook&lt;/h3&gt;&lt;p&gt;Jupyter Notebook is an interactive computing environment that allows you to create and share documents containing live code, visualizations, and explanatory text. To install Jupyter Notebook, run:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;pip install jupyter&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To start a Jupyter Notebook session, execute:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;jupyter notebook&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h3 id=&#34;step-7-additional-libraries-based-on-your-needs&#34;&gt;Step 7: Additional Libraries (Based on Your Needs)&lt;/h3&gt;&lt;p&gt;Depending on your specific data analysis requirements, you may need additional libraries. Some popular ones include:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Scikit-learn:&lt;/strong&gt; For machine learning tasks and predictive data analysis.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Statsmodels:&lt;/strong&gt; For statistical modeling and hypothesis testing.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;TensorFlow or PyTorch:&lt;/strong&gt; For deep learning and neural network implementations.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Requests:&lt;/strong&gt; For making HTTP requests to APIs and web scraping.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;BeautifulSoup:&lt;/strong&gt; For web scraping and parsing HTML/XML documents.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Openpyxl or XlsxWriter:&lt;/strong&gt; For working with Excel files.&lt;/li&gt;&lt;/ol&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Setting up a Python data environment is a vital step for anyone venturing into data analysis and data-driven decision-making. By following this comprehensive guide, you now have a robust Python environment equipped with essential libraries and tools. Python&amp;rsquo;s versatility and the vast ecosystem of libraries empower you to perform complex data manipulations, visualizations, and even advanced machine learning tasks.&lt;/p&gt;&lt;p&gt;Now, it&amp;rsquo;s time to unleash the power of Python and embark on your exciting journey into the world of data analysis! Happy coding!&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Introduction to Data Engineering: Understanding its Importance and Role in the Data Lifecycle</title>
       <link>https://saisyam.com/introduction-to-data-engineering-understanding-its-importance-and-role-in-the-data-lifecycle/</link>
       <pubDate>Sat, 29 Jul 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/introduction-to-data-engineering-understanding-its-importance-and-role-in-the-data-lifecycle/</guid>
       <description>&lt;p&gt;Data engineering is a fundamental pillar in the world of data science and analytics. It plays a pivotal role in transforming raw, unstructured data into structured, usable formats, facilitating data analysis, and enabling data-driven decision-making. In this blog post, we will delve into the concept of data engineering, exploring its importance and understanding how it fits into the data lifecycle.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#what-is-data-engineering&#34;&gt;What is Data Engineering?&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#importance-of-data-engineering&#34;&gt;Importance of Data Engineering&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#role-of-data-engineering-in-the-data-lifecycle&#34;&gt;Role of Data Engineering in the Data Lifecycle&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;what-is-data-engineering&#34;&gt;What is Data Engineering?&lt;/h2&gt;&lt;p&gt;Data engineering can be defined as the process of designing, constructing, and maintaining the systems and architectures that enable the collection, storage, and processing of data. It involves converting data from various sources into a structured format that can be easily analyzed and utilized by data scientists, analysts, and business stakeholders.&lt;/p&gt;&lt;h2 id=&#34;importance-of-data-engineering&#34;&gt;Importance of Data Engineering&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Collection and Ingestion:&lt;/strong&gt; In the data lifecycle, the first step is data collection. Data engineering plays a crucial role in gathering data from disparate sources such as databases, APIs, web scraping, IoT devices, and more. Engineers ensure that the data is ingested efficiently and securely, ensuring that it is ready for further processing.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Cleaning and Preprocessing:&lt;/strong&gt; Raw data is often messy, inconsistent, and may contain missing values. Data engineers are responsible for cleaning and preprocessing the data to eliminate errors, handle missing values, and standardize the data for analysis. This ensures that data scientists can work with high-quality, reliable data.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Storage and Management:&lt;/strong&gt; With the enormous volume of data generated daily, effective data storage and management are paramount. Data engineers design and implement databases and data warehouses that can handle large-scale data storage and retrieval. They also optimize data structures for quick querying and efficient data access.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Transformation and Integration:&lt;/strong&gt; Data engineering involves transforming data into a unified format that allows for seamless integration across multiple sources. Engineers perform data transformations, including data aggregation, normalization, and denormalization, to facilitate efficient data analysis.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Pipelines and ETL:&lt;/strong&gt; Data engineers build data pipelines, which are a series of processes that extract, transform, and load (ETL) data from source systems to the destination database or data warehouse. These pipelines automate the data flow and ensure that data is processed in real-time or batch mode, depending on the business needs.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Scalability and Performance:&lt;/strong&gt; As data volumes grow exponentially, scalability becomes a primary concern. Data engineers design systems that can handle increasing data loads while maintaining performance and reliability. This is crucial in industries where real-time data processing is essential, such as finance, e-commerce, and healthcare.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;role-of-data-engineering-in-the-data-lifecycle&#34;&gt;Role of Data Engineering in the Data Lifecycle&lt;/h2&gt;&lt;p&gt;The data lifecycle encompasses all the stages that data goes through, from its inception to its eventual archiving or deletion. Data engineering is a central player in this lifecycle, influencing each stage in the following ways:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Acquisition:&lt;/strong&gt; Data engineering teams are responsible for acquiring data from a variety of sources. They set up data pipelines and integration processes to ensure a smooth flow of data from source to destination.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Storage:&lt;/strong&gt; Engineers design and implement the storage infrastructure where data is persistently stored. This may involve selecting the appropriate database management systems (DBMS), data lakes, or data warehouses based on the nature of the data and its intended use.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Processing:&lt;/strong&gt; During the processing stage, data engineers cleanse, transform, and preprocess the data. They apply various data quality checks and data validation rules to maintain data accuracy and integrity.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Analysis:&lt;/strong&gt; Once the data is ready for analysis, data scientists and analysts use tools and techniques to gain insights from the data. Data engineering ensures that the data is organized and prepared for these analytical processes.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Visualization and Reporting:&lt;/strong&gt; After analysis, data engineers collaborate with data visualization experts to create interactive and informative dashboards and reports for business stakeholders.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Archiving and Deletion:&lt;/strong&gt; As data becomes outdated or irrelevant, data engineering is responsible for archiving or deleting the data in compliance with data retention policies and regulations.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Data engineering serves as the backbone of the data lifecycle, providing the necessary infrastructure and processes to handle data efficiently and effectively. It plays a pivotal role in collecting, storing, processing, and transforming raw data into actionable insights that drive business decisions. As organizations continue to rely on data for their operations, data engineering&amp;rsquo;s importance will only grow, making it a critical skill in the data-driven world. By understanding data engineering&amp;rsquo;s significance and its role in the data lifecycle, businesses can unlock the full potential of their data assets and stay ahead in today&amp;rsquo;s data-intensive landscape.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Generative AI for Synthetic Data Generation: Boosting Privacy and Data Quality</title>
       <link>https://saisyam.com/generative-ai-for-synthetic-data-generation-boosting-privacy-and-data-quality/</link>
       <pubDate>Sat, 22 Jul 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/generative-ai-for-synthetic-data-generation-boosting-privacy-and-data-quality/</guid>
       <description>&lt;p&gt;In the era of data-driven decision-making, organizations across various industries heavily rely on vast amounts of data to fuel their operations. However, as the value of data grows, so does the concern over data privacy and security. Traditional methods of data sharing and storage might expose sensitive information, leading to breaches and privacy violations.&lt;/p&gt;&lt;p&gt;This is where Generative AI for synthetic data generation comes into play, providing an innovative solution that strikes a balance between data utility and privacy. In this blog post, we will delve into the world of Generative AI, explore its potential for synthetic data generation, and highlight some compelling examples of its applications.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#understanding-generative-ai-and-synthetic-data-generation&#34;&gt;Understanding Generative AI and Synthetic Data Generation&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#benefits-of-synthetic-data-generation&#34;&gt;Benefits of Synthetic Data Generation&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#examples-of-generative-ai-for-synthetic-data-generation&#34;&gt;Examples of Generative AI for Synthetic Data Generation&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#lets-generate-synthetic-data-for-anonymized-user-analytics&#34;&gt;Let&amp;rsquo;s generate synthetic data for &lt;em&gt;Anonymized User Analytics&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;understanding-generative-ai-and-synthetic-data-generation&#34;&gt;Understanding Generative AI and Synthetic Data Generation&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Generative Artificial Intelligence (Generative AI)&lt;/strong&gt; refers to a subset of AI models designed to produce new content similar to the data on which they were trained. These models have shown incredible promise in various domains, including image synthesis, text generation, and more. One particular application of Generative AI that has gained significant attention is synthetic data generation.&lt;/p&gt;&lt;p&gt;Synthetic data is artificially created data that mimics the characteristics of real data but contains no identifiable information from the original dataset. This process involves using Generative AI models to generate data that approximates the statistical properties of real data. By leveraging these synthetic datasets, organizations can preserve data privacy while still extracting valuable insights and patterns.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;benefits-of-synthetic-data-generation&#34;&gt;Benefits of Synthetic Data Generation&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Privacy Protection:&lt;/strong&gt; Synthetic data allows organizations to share or analyze information without exposing sensitive details of individuals. For instance, in healthcare, researchers can use synthetic patient records to develop and validate models without risking the privacy of real patients.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Quality Enhancement:&lt;/strong&gt; Sometimes, real-world datasets might suffer from incompleteness or data imbalance, leading to biased results. Synthetic data can help overcome these issues by providing a well-balanced dataset that captures diverse scenarios.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Cost-Effective Solution:&lt;/strong&gt; Collecting and maintaining large-scale datasets can be expensive and time-consuming. Synthetic data generation offers a cost-effective alternative, enabling organizations to create virtually unlimited amounts of data.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Mitigating Legal and Ethical Concerns:&lt;/strong&gt; Strict data protection laws, such as GDPR, make it challenging to share sensitive data. Synthetic data allows organizations to comply with these regulations while still enabling collaboration and research.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;examples-of-generative-ai-for-synthetic-data-generation&#34;&gt;Examples of Generative AI for Synthetic Data Generation&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Autonomous Vehicles Training&lt;/strong&gt;Training self-driving cars requires massive amounts of diverse data to ensure safe and reliable performance. However, sharing real-world driving data could jeopardize the privacy of individuals captured in the recordings. By using Generative AI models, companies can create synthetic datasets that simulate various driving scenarios, road conditions, and traffic situations without compromising real individuals&#39; identities.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Healthcare Research&lt;/strong&gt;Medical research often relies on large-scale datasets to develop new treatments and understand diseases. However, patient data must be protected to maintain confidentiality. Synthetic data generation enables researchers to create synthetic patient records, including demographics, medical history, and imaging data, which can be shared with other institutions without violating patient privacy.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Financial Fraud Detection&lt;/strong&gt;Banks and financial institutions need reliable data to train fraud detection algorithms effectively. Synthetic data can be generated to simulate fraudulent transactions and patterns while avoiding the use of real customer data. This approach ensures privacy while improving the accuracy of fraud detection systems.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Anonymized User Analytics&lt;/strong&gt;In the realm of online services and social media platforms, user data is crucial for personalization and analytics. However, privacy concerns arise when sharing user data with third parties. With synthetic data, platforms can share anonymized and privacy-safe datasets with advertisers and researchers, safeguarding user privacy while maintaining data utility.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;lets-generate-synthetic-data-for-anonymized-user-analytics&#34;&gt;Let&amp;rsquo;s generate synthetic data for &lt;em&gt;Anonymized User Analytics&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;For this example, we will use OpenAI&amp;rsquo;s GPT API to generate synthetic user analytics data.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 1: Define the Prompt&lt;/strong&gt;To start, we need to define the prompt that will instruct the Generative AI model to generate anonymized user analytics data. The prompt should specify the data format and the type of information we want to generate. Here&amp;rsquo;s an example prompt:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;Prompt: Generate synthetic anonymized &lt;span style=&#34;color:#66d9ef&#34;&gt;user&lt;/span&gt; analytics &lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; a social media platform.Format: &lt;span style=&#34;color:#66d9ef&#34;&gt;Each&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;row&lt;/span&gt; should represent a &lt;span style=&#34;color:#66d9ef&#34;&gt;user&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; the following attributes:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;User&lt;/span&gt; ID: a &lt;span style=&#34;color:#66d9ef&#34;&gt;unique&lt;/span&gt; identifier &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;each&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;user&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Age: a random age &lt;span style=&#34;color:#66d9ef&#34;&gt;between&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;18&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;and&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;65&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Gender: randomly assigned &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Male&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Female&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Location&lt;/span&gt;: a random city &lt;span style=&#34;color:#66d9ef&#34;&gt;from&lt;/span&gt; a predefined list&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Number &lt;span style=&#34;color:#66d9ef&#34;&gt;of&lt;/span&gt; Posts: a random value &lt;span style=&#34;color:#66d9ef&#34;&gt;between&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;and&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Likes: a random value &lt;span style=&#34;color:#66d9ef&#34;&gt;between&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;and&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Followers: a random value &lt;span style=&#34;color:#66d9ef&#34;&gt;between&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;and&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Step 2: API Call&lt;/strong&gt;Now, we will make an API call to OpenAI&amp;rsquo;s GPT API using the prompt we defined. Make sure you have your OpenAI API key ready for authentication. Below is an example Python code using the &lt;code&gt;openai&lt;/code&gt; library for the API call:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; openai&lt;span style=&#34;color:#75715e&#34;&gt;# Replace &amp;#39;YOUR_API_KEY&amp;#39; with your actual OpenAI API key&lt;/span&gt;api_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;YOUR_API_KEY&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Define the prompt&lt;/span&gt;prompt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Generate synthetic anonymized user analytics data for a social media platform.&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Format: Each row should represent a user with the following attributes:&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- User ID: a unique identifier for each user&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Age: a random age between 18 and 65&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Gender: randomly assigned as &amp;#34;Male&amp;#34; or &amp;#34;Female&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Location: a random city from a predefined list&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Number of Posts: a random value between 1 and 100&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Likes: a random value between 1 and 500&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Followers: a random value between 0 and 5000&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Make the API call to GPT&lt;/span&gt;openai&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;api_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; api_keyresponse &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; openai&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Completion&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create(    engine&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;text-davinci-002&amp;#34;&lt;/span&gt;,    prompt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;prompt,    max_tokens&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,    n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# Generating 10 rows of synthetic data&lt;/span&gt;    stop&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,    temperature&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;)&lt;span style=&#34;color:#75715e&#34;&gt;# Extract and print the generated synthetic data&lt;/span&gt;synthetic_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; response[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;choices&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;]print(synthetic_data)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note: You need an API key from &lt;code&gt;openAI&lt;/code&gt; to run the above code. OpenAI charges on pay-per-use basis. You can get your key from &lt;a href=&#34;https://openai.com&#34;&gt;here&lt;/a&gt; after sign-up.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 3: Process the Response&lt;/strong&gt;The response from the API call will contain the generated synthetic data. The &lt;code&gt;synthetic_data&lt;/code&gt; variable will hold the generated data in the specified format. You can then process this data and save it in a suitable format, such as a CSV file or a database.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Example Output:&lt;/em&gt;Here&amp;rsquo;s an example of what the generated synthetic data might look like:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;User ID,Age,Gender,Location,Number of Posts,Likes,Followers,Following&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;21&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Female,New York,22,196,3201,283&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Male,Los Angeles,45,325,5120,215&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;18&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Female,Chicago,76,425,3652,482&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;43&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Male,Houston,21,84,1474,299&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Female,Phoenix,93,354,2134,367&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Male,Philadelphia,67,452,3890,211&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;36&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Female,San Antonio,78,321,5234,487&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;39&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Male,San Diego,43,234,4120,298&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;51&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Female,Dallas,59,452,4098,256&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;27&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;Male,San Jose,81,356,4212,573&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Please note that the above example is just a small sample of the generated data. You can generate as many rows as needed by adjusting the n parameter in the API call.&lt;/p&gt;&lt;p&gt;In this example, we successfully used Generative AI prompts with OpenAI&amp;rsquo;s GPT API to generate synthetic anonymized user analytics data for a social media platform. Synthetic data like this can be used for various purposes, such as testing and development, analytics, and research, without compromising the privacy of real users. &lt;strong&gt;Always remember to handle synthetic data responsibly and ensure it complies with relevant privacy and data protection regulations.&lt;/strong&gt;&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Generative AI for synthetic data generation presents a compelling solution to the ongoing challenges of data privacy and data quality. By leveraging advanced Generative AI models, organizations can strike a delicate balance between the need for accurate data and the imperative to protect sensitive information. The examples discussed in this blog post demonstrate the immense potential of synthetic data generation in revolutionizing various industries, enabling them to make data-driven decisions without compromising privacy. As Generative AI continues to advance, we can expect even more innovative applications that will shape the future of data-driven technologies.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Unlocking Data Visualization Power: A Comprehensive Guide to Python Dash with Bootstrap</title>
       <link>https://saisyam.com/unlocking-data-visualization-power-a-comprehensive-guide-to-python-dash-with-bootstrap/</link>
       <pubDate>Thu, 29 Jun 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/unlocking-data-visualization-power-a-comprehensive-guide-to-python-dash-with-bootstrap/</guid>
       <description>&lt;p&gt;In today&amp;rsquo;s fast-paced digital age, visualizing and understanding complex data is of paramount importance. Dash, a Python-based framework, is an incredible tool for building analytical applications with ease. In this article, we will dive into Dash, explore its potential, and learn how to create intuitive, styled applications using Dash Bootstrap Components.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#understanding-dash-in-python&#34;&gt;Understanding Dash in Python&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#exploring-dash-bootstrap-components&#34;&gt;Exploring Dash Bootstrap Components&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#building-a-dash-application-a-basic-example&#34;&gt;Building a Dash Application: A Basic Example&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#building-a-dash-application-complex-graphs-example&#34;&gt;Building a Dash Application: Complex Graphs Example&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;understanding-dash-in-python&#34;&gt;Understanding Dash in Python&lt;/h2&gt;&lt;p&gt;Dash is an open-source Python framework used to build analytical web applications. Unlike other Python libraries such as Matplotlib or Seaborn, Dash is unique because it translates your Python code into HTML and JavaScript. This means you can create powerful, interactive applications without any knowledge of web development languages.&lt;/p&gt;&lt;p&gt;One of the exciting facets of Dash is its ability to create dynamic applications, thanks to its reactive programming structure. Reactive programming means that your Dash application will automatically update and respond to any changes in your input data, making it incredibly powerful for interactive data visualization and analysis.&lt;/p&gt;&lt;h2 id=&#34;exploring-dash-bootstrap-components&#34;&gt;Exploring Dash Bootstrap Components&lt;/h2&gt;&lt;p&gt;Dash Bootstrap Components are a set of components that help style your Dash application in an aesthetic and user-friendly manner. They offer the versatility of the Bootstrap CSS framework to your Dash applications. With these, you can easily implement common Bootstrap elements such as grids, cards, dropdowns, and more. They make your Dash apps responsive and compatible across different screen sizes.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;building-a-dash-application-a-basic-example&#34;&gt;Building a Dash Application: A Basic Example&lt;/h2&gt;&lt;p&gt;In our first example, let&amp;rsquo;s create a simple Dash application that displays a welcoming message. Make sure you&amp;rsquo;ve installed Dash and the Dash Bootstrap Components by using pip:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ pip install dash dash-bootstrap-components&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is a barebones Dash application:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; dash&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; dash_bootstrap_components &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; dbc&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; dash &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; htmlapp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dash&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dash(__name__, external_stylesheets&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[dbc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;themes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;BOOTSTRAP])app&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; html&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Div(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello, Dash!&amp;#34;&lt;/span&gt;, className&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;p-5&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:    app&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run_server(debug&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run the above application using the below command:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ python3 app.py&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above application will display the text &amp;ldquo;Hello, Dash!&amp;rdquo; on your localhost.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;building-a-dash-application-complex-graphs-example&#34;&gt;Building a Dash Application: Complex Graphs Example&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s delve deeper and create a Dash application that includes two interactive graphs using Plotly and styled with Dash Bootstrap Components. To demonstrate this, we&amp;rsquo;ll use a classic dataset: the Iris dataset.&lt;/p&gt;&lt;p&gt;First, install necessary packages, Dash, Plotly, and Dash Bootstrap Components:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ pip install dash dash-bootstrap-components plotly pandas&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, let&amp;rsquo;s load our dataset and start building our application:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; dash&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; dash_bootstrap_components &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; dbc&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; dash &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; dcc&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; dash &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; html&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; dash.dependencies &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Input, Output&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; plotly.express &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; px&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pddf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv&amp;#39;&lt;/span&gt;)app &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dash&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dash(__name__, external_stylesheets&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[dbc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;themes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;BOOTSTRAP])app&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; html&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Div([    dbc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Row([        dbc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Col([            dcc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Graph(id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scatter&amp;#39;&lt;/span&gt;, config&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;displayModeBar&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;}),        ], md&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;),        dbc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Col([            dcc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Graph(id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;box&amp;#39;&lt;/span&gt;, config&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;displayModeBar&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;}),        ], md&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)    ]),    dbc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Row([        dbc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Col([            dcc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropdown(id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;species&amp;#39;&lt;/span&gt;,                         options&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;label&amp;#39;&lt;/span&gt;: i, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;value&amp;#39;&lt;/span&gt;: i} &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;species&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()],                         value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;setosa&amp;#39;&lt;/span&gt;)        ])    ])])&lt;span style=&#34;color:#a6e22e&#34;&gt;@app&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;callback(    Output(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scatter&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;figure&amp;#39;&lt;/span&gt;),    Output(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;box&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;figure&amp;#39;&lt;/span&gt;),    Input(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;species&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;value&amp;#39;&lt;/span&gt;))&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;update_graphs&lt;/span&gt;(species):    dff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;species &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; species]    scatter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; px&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(dff, x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sepal_length&amp;#39;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sepal_width&amp;#39;&lt;/span&gt;, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;species&amp;#39;&lt;/span&gt;)    box &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; px&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;box(dff, x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;species&amp;#39;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;petal_length&amp;#39;&lt;/span&gt;)        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; scatter, box&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:    app&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run_server(debug&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this application, we have two graphs - a scatter plot and a box plot. The scatter plot visualizes the sepal length and width of different iris species. The box plot shows the distribution of petal length for the selected species. A dropdown list allows us to choose a specific species, and our graphs will reactively update according to our selection.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Dash opens the gateway to creating interactive, data-centric web applications using just Python. When coupled with Dash Bootstrap Components, the result is aesthetically pleasing and responsive applications, perfectly suited for today&amp;rsquo;s multi-screen world.&lt;/p&gt;&lt;p&gt;We&amp;rsquo;ve used Dash and Dash Bootstrap Components to build a complex interactive application showcasing iris species data. We learned how to create and style multiple graphs and implement a dropdown selection component to manipulate these graphs dynamically.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Testing Nested SQLAlchemy Queries with Pytest</title>
       <link>https://saisyam.com/testing-nested-sqlalchemy-queries-with-pytest/</link>
       <pubDate>Fri, 23 Jun 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/testing-nested-sqlalchemy-queries-with-pytest/</guid>
       <description>&lt;p&gt;Unit testing is a crucial component of software development, ensuring individual pieces of code perform as expected. When working with SQLAlchemy, a popular SQL toolkit and Object-Relational Mapping (ORM) system for Python, testing the queries you write is important. In this blog post, we will delve into an advanced method for unit testing nested SQLAlchemy queries using Pytest and pytest-mock.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#prerequisites&#34;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#the-challenge-with-unit-testing-nested-sqlalchemy-queries&#34;&gt;The Challenge with Unit Testing Nested SQLAlchemy Queries&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#solution-mocking-nested-sqlalchemy-queries-with-pytest-mock&#34;&gt;Solution: Mocking Nested SQLAlchemy Queries with pytest-mock&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;&lt;p&gt;For this post, we presume you have a fundamental understanding of Python, SQLAlchemy, and unit testing. We will be using Pytest, a robust testing framework for Python, and pytest-mock, a thin wrapper around the unittest.mock module that integrates seamlessly with Pytest fixtures.&lt;/p&gt;&lt;h2 id=&#34;the-challenge-with-unit-testing-nested-sqlalchemy-queries&#34;&gt;The Challenge with Unit Testing Nested SQLAlchemy Queries&lt;/h2&gt;&lt;p&gt;Writing unit tests for SQLAlchemy models often involves testing methods that run complex, nested queries. Such queries might use method chaining, like &lt;code&gt;session.query(Model).filter(...).order_by(...).paginate(...)&lt;/code&gt;. The complexity arises from the fact that each method in the chain returns a new query object, incorporating constraints from all previous methods.&lt;/p&gt;&lt;p&gt;Say you want to test a query that uses the order_by and filter methods. While you may aim to mock the order_by method, this won&amp;rsquo;t be sufficient because the object it returns needs to also include a filter method. This complexity makes accurate mocking a challenge.&lt;/p&gt;&lt;h2 id=&#34;solution-mocking-nested-sqlalchemy-queries-with-pytest-mock&#34;&gt;Solution: Mocking Nested SQLAlchemy Queries with pytest-mock&lt;/h2&gt;&lt;p&gt;Pytest-mock offers a streamlined solution by providing a &lt;code&gt;mocker&lt;/code&gt; fixture. This fixture, a thin-wrapper around &lt;code&gt;unittest.mock&lt;/code&gt;, integrates more smoothly with Pytest. We can use &lt;code&gt;mocker&lt;/code&gt; to individually mock each method in the chain.&lt;/p&gt;&lt;p&gt;Let&amp;rsquo;s consider an example where we aim to mock the following chain: &lt;code&gt;app.model.Project.query.order_by.filter.paginate&lt;/code&gt;.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;test_example&lt;/span&gt;(mocker):    paginate_mock &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mocker&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Mock()  &lt;span style=&#34;color:#75715e&#34;&gt;# New mock for &amp;#39;paginate&amp;#39;&lt;/span&gt;    filter_mock &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mocker&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Mock()    filter_mock&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;paginate&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;return_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; paginate_mock  &lt;span style=&#34;color:#75715e&#34;&gt;# We replace &amp;#39;filter.paginate&amp;#39; with &amp;#39;paginate_mock&amp;#39;&lt;/span&gt;        order_by_mock &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mocker&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Mock()    order_by_mock&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;return_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; filter_mock  &lt;span style=&#34;color:#75715e&#34;&gt;# We replace &amp;#39;order_by.filter&amp;#39; with &amp;#39;filter_mock&amp;#39;&lt;/span&gt;    query_mock &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mocker&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Mock()    query_mock&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;order_by&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;return_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; order_by_mock  &lt;span style=&#34;color:#75715e&#34;&gt;# We replace &amp;#39;query.order_by&amp;#39; with &amp;#39;order_by_mock&amp;#39;&lt;/span&gt;    mocker&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;patch(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;app.model.Project.query&amp;#39;&lt;/span&gt;, new&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;query_mock)    &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this example, we&amp;rsquo;ve created a separate mock for each method in the chain: &lt;code&gt;query&lt;/code&gt;, &lt;code&gt;order_by&lt;/code&gt;, &lt;code&gt;filter&lt;/code&gt;, and &lt;code&gt;paginate&lt;/code&gt;. Each mock replaces the method that follows it in the chain. This means that when you call &lt;code&gt;app.model.Project.query.order_by&lt;/code&gt;, you get the &lt;code&gt;order_by_mock&lt;/code&gt;, when you call &lt;code&gt;app.model.Project.query.order_by.filter&lt;/code&gt;, you get the &lt;code&gt;filter_mock&lt;/code&gt;, and so forth.&lt;/p&gt;&lt;p&gt;These mocks can then be set up to return values suited to your test. You can specify a return value for each method to simulate your actual database&amp;rsquo;s response to the query.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Unit testing is a vital part of software development, and testing database queries is no exception. Although testing nested SQLAlchemy queries can be challenging due to their complexity and dependence on method chaining, we&amp;rsquo;ve seen that pytest-mock can offer a helpful solution. It allows us to mock individual methods in the query chain and customize them to return the results we want.&lt;/p&gt;&lt;p&gt;However, while useful in certain scenarios, this approach can lead to brittle tests that are highly dependent on the internals of SQLAlchemy. In many cases, higher-level tests can be a more robust and future-proof solution. By testing against a known set of data in a test database, we can verify the actual behavior of our code, without having to worry about the intricacies of SQLAlchemy&amp;rsquo;s implementation.&lt;/p&gt;&lt;p&gt;Regardless of the method you choose, the key is to ensure your tests are thorough, maintainable, and accurately reflect the requirements of your application. Happy testing!&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Loading Yelp Dataset into Snowflake: A Comprehensive Guide</title>
       <link>https://saisyam.com/loading-yelp-dataset-into-snowflake-a-comprehensive-guide/</link>
       <pubDate>Sun, 28 May 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/loading-yelp-dataset-into-snowflake-a-comprehensive-guide/</guid>
       <description>&lt;p&gt;In this blog post, we will explore how to load the Yelp dataset, which comprises business, review, and user information, into Snowflake - a cloud-based data warehousing platform. The Yelp dataset is a popular dataset used by data enthusiasts and professionals worldwide to perform analysis and build models around review systems.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#prerequisites&#34;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#preparing-yelp-dataset&#34;&gt;Preparing Yelp Dataset&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#create-database-and-tables-in-snowflake-for-business-and-review&#34;&gt;Create database and tables in Snowflake for business and review&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#upload-yelp-files-to-snowflake-stage&#34;&gt;Upload Yelp files to Snowflake stage&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#load-these-json-files-from-stage-into-the-tables&#34;&gt;Load these JSON files from stage into the tables&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;&lt;p&gt;To follow this guide, you&amp;rsquo;ll need:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Snowflake Account:&lt;/strong&gt; You can create one on the &lt;a href=&#34;https://snowflake.com&#34;&gt;Snowflake website&lt;/a&gt;. The basic tier should suffice for learning purposes.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Yelp Dataset:&lt;/strong&gt; You can download the Yelp dataset &lt;a href=&#34;https://www.yelp.com/dataset&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;SnowSQL:&lt;/strong&gt; This is Snowflake&amp;rsquo;s command line interface. Download it from &lt;a href=&#34;https://docs.snowflake.com/en/user-guide/snowsql-install-config.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&#34;preparing-yelp-dataset&#34;&gt;Preparing Yelp Dataset&lt;/h2&gt;&lt;p&gt;Yelp dataset contains data related to business, checkins, reviews, users and tips. But we are interested in the following files:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;yelp_academic_dataset_business.json&lt;/strong&gt; - List of around 150k business with location, working hours, categories etc.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;yelp_academic_dataset_review.json&lt;/strong&gt; - Around 6M reviews related to the businesses mentioned in the above file&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We follow below steps to load these JSON files into Snowflake.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Create Database and tables in Snowflake for business, review and user&lt;/li&gt;&lt;li&gt;Upload these json file to Snowflake stage&lt;/li&gt;&lt;li&gt;Load these JSON files from stage into the tables&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Let&amp;rsquo;s go step by step in getting Yelp data to Snowflake.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;create-database-and-tables-in-snowflake-for-business-and-review&#34;&gt;Create database and tables in Snowflake for business and review&lt;/h2&gt;&lt;p&gt;Once you analyze the JSON files you will understand what type of data they are capturing and create table structure based on that. Below are the Snowflake SQL commands to create tables for business, review and user.&lt;/p&gt;&lt;p&gt;Create a database in Snowflake:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; yelp;USE &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; yelp;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;SCHEMA&lt;/span&gt; dataset;USE &lt;span style=&#34;color:#66d9ef&#34;&gt;SCHEMA&lt;/span&gt; dataset;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I use &lt;code&gt;public&lt;/code&gt; schema. Make sure you grant necessary permissions to read/write.&lt;/p&gt;&lt;p&gt;SQL for business:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; business_info (    business_id STRING,    name STRING,    address STRING,    city STRING,    &lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt; STRING,    postal_code STRING,    latitude FLOAT,    longitude FLOAT,    stars FLOAT,    review_count INTEGER,    is_open BOOLEAN,    attributes VARIANT,    categories STRING,    hours VARIANT);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;SQL for reviews:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; reviews (    review_id STRING,    user_id STRING,    business_id STRING,    stars FLOAT,    useful INTEGER,    funny INTEGER,    cool INTEGER,    text STRING,    date TIMESTAMP_NTZ);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Reviews JSON is more than 1 GB which is difficult to open in an editor. If you are using Linux/Mac then you can use the &lt;code&gt;more&lt;/code&gt; terminal command to check the sample data in those large files.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ more yelp_academic_dataset_review.json&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;review_id&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KU_O5udG6zpxOg-VcAEodg&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;user_id&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mh_-eMZ6K5RLWhZyISBhwA&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;business_id&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;XQfwVwDr-v0ZS3_CbbE5Xw&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stars&amp;#34;&lt;/span&gt;:3.0,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;useful&amp;#34;&lt;/span&gt;:0,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;funny&amp;#34;&lt;/span&gt;:0,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cool&amp;#34;&lt;/span&gt;:0,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;If you decide to eat here, just be aware it is going to take about 2 hours from beginning to end. We have tried it multiple times, because I want to like it! I have been to it&amp;#39;s other locations in NJ and never had a bad experience. \n\nThe food is good, but it takes a very long time to come out. The waitstaff is very young, but usually pleasant. We have just had too many experiences where we spent way too long waiting. We usually opt for another diner or restaurant on the weekends, in order to be done quicker.&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;date&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2018-07-07 22:09:11&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;upload-yelp-files-to-snowflake-stage&#34;&gt;Upload Yelp files to Snowflake stage&lt;/h2&gt;&lt;p&gt;You can use Snowflake web UI as well to create stage.&lt;/p&gt;&lt;p&gt;Let&amp;rsquo;s login to &lt;code&gt;SnowSQL&lt;/code&gt;:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;snowsql -a &amp;lt;account url&amp;gt; -u &amp;lt;usernmae&amp;gt; -d &amp;lt;database name&amp;gt; -s &amp;lt;schema name&amp;gt; -r &amp;lt;role&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It will prompt for the password. On successful login, you will be taken to the SnowSQL prompt, like this:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;sdampuri#DEMO_WH@YELP_DATASET.PUBLIC&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We will use &lt;code&gt;SnowSQL&lt;/code&gt; to upload JSON files to Snowflake stage. Let&amp;rsquo;s create a stage first:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; STAGE yelp_stageFILE_FORMAT &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;TYPE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;JSON&amp;#39;&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have the stage created we can upload the files. Make sure you have necessary permissions to upload to this stage.Now let&amp;rsquo;s upload the files to the above stage using &lt;code&gt;PUT&lt;/code&gt; command:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;put file:///Users/saisyam/work/yelp_dataset/yelp_academic_dataset_business.json @YELP_STAGE AUTO_COMPRESS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;FALSE;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Yes, I want to keep my JSON uncompressed even the size is large. The upload will depend on your Internet speed.&lt;/p&gt;&lt;h2 id=&#34;load-these-json-files-from-stage-into-the-tables&#34;&gt;Load these JSON files from stage into the tables&lt;/h2&gt;&lt;p&gt;We can load the JSON files from stage to table using &lt;code&gt;COPY&lt;/code&gt; command:&lt;/p&gt;&lt;p&gt;To load businesses into table:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;COPY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;INTO&lt;/span&gt; business_info&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; (    &lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;         &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:business_id::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:name::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:address::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:city::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:&lt;span style=&#34;color:#66d9ef&#34;&gt;state&lt;/span&gt;::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:postal_code::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:latitude::float,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:longitude::float,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;: stars::float,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:review_count::integer,        IFF(&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:is_open::integer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;TRUE&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;FALSE&lt;/span&gt;),        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:attributes,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:categories::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:hours    &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;yelp_stage&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;yelp_academic_dataset_business.json);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To load reviews into table:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;COPY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;INTO&lt;/span&gt; reviews&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; (    &lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;         &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:review_id::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:user_id::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:business_id::string,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;: stars::float,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:useful::integer,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:funny::integer,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;: cool::integer,        &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:text::string,        TO_TIMESTAMP(&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;: date::string, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;YYYY-MM-DD HH24:MI:SS&amp;#39;&lt;/span&gt;)    &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;yelp_stage&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;yelp_academic_dataset_review.json);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It took 3.37s to load 6,990,280 rows into the reviews table using &lt;code&gt;X-SMALL&lt;/code&gt; warehouse. Now we have the data ready to perform analytics.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In this blog post, we discussed the steps to load the Yelp dataset, which contains business, review, and user information, into Snowflake. Following this guide, you should be able to load this data into Snowflake for your own projects. The process involves data preprocessing, setting up staging area in Snowflake, and then loading the data into Snowflake using the COPY INTO command. Happy data loading!&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Data Testing with Great Expectations: An Introduction to In-Memory Context</title>
       <link>https://saisyam.com/data-testing-with-great-expectations-an-introduction-to-in-memory-context/</link>
       <pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/data-testing-with-great-expectations-an-introduction-to-in-memory-context/</guid>
       <description>&lt;p&gt;In the world of data science and data engineering, ensuring the quality and integrity of your data is crucial. One tool that can help with this is Great Expectations, a Python library that allows you to test your data against a set of &amp;ldquo;expectations&amp;rdquo;. In this blog post, we&amp;rsquo;ll explore a particular feature of Great Expectations: the in-memory context.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#what-is-great-expectations&#34;&gt;What is Great Expectations?&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#the-in-memory-context&#34;&gt;The In-Memory Context&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;what-is-great-expectations&#34;&gt;What is Great Expectations?&lt;/h2&gt;&lt;p&gt;Great Expectations is a Python library that helps data teams eliminate pipeline debt. It does this by enabling automated testing of data quality and documentation of data. With Great Expectations, you can express what you &amp;ldquo;expect&amp;rdquo; from your data as simple, human-readable assertions. &lt;a href=&#34;https://saisyam.com/unlock-quality-insights-with-great-expectations-python-library/&#34;&gt;Here&lt;/a&gt; is my blog about Great Expectations in detail.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; great_expectations &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; ge&lt;span style=&#34;color:#75715e&#34;&gt;# Load some data&lt;/span&gt;df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ge&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#75715e&#34;&gt;# Set an expectation&lt;/span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expect_column_values_to_be_unique(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;the-in-memory-context&#34;&gt;The In-Memory Context&lt;/h2&gt;&lt;p&gt;One of the features of Great Expectations is the DataContext. A DataContext represents a Great Expectations project and includes many features for configuring and managing your data expectations.&lt;/p&gt;&lt;p&gt;In version 0.13.8, Great Expectations introduced the InMemoryDataContext. This allows you to create a DataContext that doesn&amp;rsquo;t require a filesystem. This can be particularly useful for testing or for situations where you don&amp;rsquo;t want to or can&amp;rsquo;t write to disk.You can create a in memory data context using the build-in method from Great Expectations.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; great_expectations.util &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;context &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; build_in_memory_runtime_context()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The full working code, with &lt;code&gt;datasource config&lt;/code&gt;, &lt;code&gt;expectation suite&lt;/code&gt;, &lt;code&gt;batch request&lt;/code&gt; and &lt;code&gt;checkpoints&lt;/code&gt;:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; great_expectations &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; ge&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; great_expectations.util &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; great_expectations.core.batch &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; RuntimeBatchRequest&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; great_expectations.core.expectation_configuration &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ExpectationConfiguration&lt;span style=&#34;color:#75715e&#34;&gt;# Load some data&lt;/span&gt;df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ge&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;)context &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; build_in_memory_runtime_context()datasource_config &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;orders_datasource&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Datasource&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;module_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;great_expectations.datasource&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;execution_engine&amp;#34;&lt;/span&gt;: {        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;module_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;great_expectations.execution_engine&amp;#34;&lt;/span&gt;,        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PandasExecutionEngine&amp;#34;&lt;/span&gt;,    },    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data_connectors&amp;#34;&lt;/span&gt;: {        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_runtime_data_connector_name&amp;#34;&lt;/span&gt;: {            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RuntimeDataConnector&amp;#34;&lt;/span&gt;,            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;module_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;great_expectations.datasource.data_connector&amp;#34;&lt;/span&gt;,            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch_identifiers&amp;#34;&lt;/span&gt;: [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_identifier_name&amp;#34;&lt;/span&gt;],        },    },}context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_datasource(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;datasource_config)&lt;span style=&#34;color:#75715e&#34;&gt;# Create expectations suite and add expectations&lt;/span&gt;suite &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create_expectation_suite(expectation_suite_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my_suite&amp;#34;&lt;/span&gt;, overwrite_existing&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)expectation_config &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ExpectationConfiguration(    expectation_type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;expect_column_values_to_be_unique&amp;#34;&lt;/span&gt;,    kwargs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;column&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ORDERNUMBER&amp;#34;&lt;/span&gt;    }) suite&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_expectation(expectation_configuration&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;expectation_config)context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save_expectation_suite(suite, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my_suite&amp;#34;&lt;/span&gt;)batch_request &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RuntimeBatchRequest(    datasource_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;orders_datasource&amp;#34;&lt;/span&gt;,    data_connector_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_runtime_data_connector_name&amp;#34;&lt;/span&gt;,    data_asset_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;orders&amp;#34;&lt;/span&gt;,    runtime_parameters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch_data&amp;#34;&lt;/span&gt;:df},    batch_identifiers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_identifier_name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_identifier&amp;#34;&lt;/span&gt;})checkpoint_config &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;orders_checkpoint&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;config_version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SimpleCheckpoint&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;expectation_suite_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my_suite&amp;#34;&lt;/span&gt;}context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_checkpoint(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;checkpoint_config)results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run_checkpoint(    checkpoint_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;orders_checkpoint&amp;#34;&lt;/span&gt;,    validations&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[        {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch_request&amp;#34;&lt;/span&gt;: batch_request}    ])print(results)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Great Expectations is a powerful tool for ensuring data quality, and the in-memory context feature provides even more flexibility for data testing. Whether you&amp;rsquo;re working in a robust data engineering environment or just doing some quick data quality checks, Great Expectations and its in-memory context can be a valuable addition to your data toolkit.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Unlock Quality Insights with Great Expectations Python Library</title>
       <link>https://saisyam.com/unlock-quality-insights-with-great-expectations-python-library/</link>
       <pubDate>Sat, 31 Dec 2022 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/unlock-quality-insights-with-great-expectations-python-library/</guid>
       <description>&lt;p&gt;Poor data quality can be a major issue for businesses, resulting in costly errors and incorrect decisions being made. To avoid these problems, it is important to take steps to ensure the quality of data being used. One way to do this is to implement a data quality solution such as &lt;a href=&#34;https://greatexpectations.io/&#34;&gt;Great Expectations&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;With this tool, users can quickly and easily identify data quality issues and ensure that their data is of the highest quality. Additionally, Great Expectations has a built-in testing framework that allows users to quickly write and execute tests on their data. This makes it easier to maintain data quality over time and ensure that data is always up to date and correct. By implementing a data quality solution like Great Expectations, businesses can ensure that their data is of the highest quality and that costly errors and incorrect decisions are avoided.&lt;/p&gt;&lt;p&gt;In this article we will discuss how to setup Great Expectations and apply expectations or rules on a sample dataset. Data engineers can use Great Expectations in different ways. In this post we will discuss code based approach instead of command line approach.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#what-is-great-expectations&#34;&gt;What is Great Expectations?&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#getting-started&#34;&gt;Getting started&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#how-great-expectations-work&#34;&gt;How Great Expectations work&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#installing-great-expectations&#34;&gt;Installing Great Expectations&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#setting-up-the-data-context&#34;&gt;Setting up the Data context&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#setting-up-data-source&#34;&gt;Setting up data source&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#creating-expectation-suite-and-add-expectations-to-it&#34;&gt;Creating Expectation suite and add Expectations to it&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#create-dataset-and-run-checkpoint&#34;&gt;Create dataset and run checkpoint&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;what-is-great-expectations&#34;&gt;What is Great Expectations?&lt;/h2&gt;&lt;p&gt;The definition from Great Expectations website:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Great Expectations is a Python-based open-source library for validating, documenting, and profiling your data. It helps you to maintain data quality and improve communication about data between teams.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Great Expectations is like unittests for your data. With Great Expectations you can assert what you expect from the data you load and transform. The main features of Great Expectations for Data engineers are:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Assert data from other teams or vendors and ensure its validity&lt;/li&gt;&lt;li&gt;Easily integrates into your pipelines in Databricks and Apache Spark&lt;/li&gt;&lt;li&gt;Supports different dataset types - Pandas Dataframe, Spark Dataframe and Databases with SQLAlchemy&lt;/li&gt;&lt;li&gt;Generates metrics and documentation for the results&lt;/li&gt;&lt;li&gt;Provides support to create custom expectations and custom actions to move invalid data to other locations&lt;/li&gt;&lt;li&gt;Integrates seamlessly with DAG execution tools like &lt;a href=&#34;https://airflow.apache.org&#34;&gt;Airflow&lt;/a&gt;, &lt;a href=&#34;https://www.getdbt.com&#34;&gt;dbt&lt;/a&gt;, &lt;a href=&#34;https://prefect.io&#34;&gt;Prefect&lt;/a&gt;, &lt;a href=&#34;https://github.com/dagster-io/dagster&#34;&gt;Dagster&lt;/a&gt;, &lt;a href=&#34;https://github.com/quantumblacklabs/kedro&#34;&gt;Kendro&lt;/a&gt; etc.&lt;/li&gt;&lt;/ol&gt;&lt;h2 id=&#34;getting-started&#34;&gt;Getting started&lt;/h2&gt;&lt;p&gt;The key feature of Great Expectaions is the &lt;a href=&#34;https://docs.greatexpectations.io/docs/#expectations&#34;&gt;Expectations&lt;/a&gt;. Expectations are assertions about your data. In Great Expectations, expectations are nothing but Python methods. For example, in order to assert that you want the column &amp;ldquo;id&amp;rdquo; to be unique, you can say:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;expect_column_value_to_be_unique(    column&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Great Expectations provides such kind of expectations out-of-the-box. If you don&amp;rsquo;t find the expectation you want, you can always write your own expectation. Writing &lt;a href=&#34;https://docs.greatexpectations.io/docs/guides/expectations/creating_custom_expectations/overview&#34;&gt;custom expectations&lt;/a&gt; needs a separate post and hence not in the scope of this article.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;how-great-expectations-work&#34;&gt;How Great Expectations work&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s discuss at a high level how this framework works. Once you install the Great expectations pip package you need to setup the following:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Data context&lt;/strong&gt; - Data context defines all the configurations required for Great Expectations to work. The two important things you define in data context are data sources and stores.&lt;ol&gt;&lt;li&gt;Great Expectations stores your expectations, checkpoints and results in a store. The store can be your file system, an AWS S3 bucket, an Azure blob or Google cloud storage. In this article we will use file system as backendstore.&lt;/li&gt;&lt;li&gt;You have to define which data source you want to apply your expectations. Great Expectations support Pandas dataframe, Spark dataframe and database tables with SQLAlchemy support. In this article we will use Pandas dataframe.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Expectations suite&lt;/strong&gt; - An expectation suite contains a set of expectations you want to run on a dataset. You give an expectations suite a valid name so that you can identify what expectations are added to this suite.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Expectation&lt;/strong&gt; - Expectation is an assertion or rule that you want to apply on a specific column in your dataset. For example, checking whether the value in the column is in the set of values provided.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Checkpoints&lt;/strong&gt; - A checkpoint is a feature in the Great Expectations library that allows you to save the state of your data validation so that you can quickly resume at that point in the future. A checkpoint also allows you to compare data validation results over time. You can define custom checkpoints with custom actions (like storing the failed records in an S3 bucket).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Data docs&lt;/strong&gt; - The Great Expectations Python library provides a variety of data docs to help users understand their data and the data expectations they have set. These data docs include:&lt;ol&gt;&lt;li&gt;Data Documentation: This provides an overview of the data, including information about the data sources, data types, data quality, and more.&lt;/li&gt;&lt;li&gt;Data Profiling: This provides an in-depth view of the data, including information about the distribution, outliers, missing values, and more.&lt;/li&gt;&lt;li&gt;Data Expectations Reports: This provides an overview of the data expectations that have been set, the results of tests against the expectations, and any issues that have been identified.&lt;/li&gt;&lt;li&gt;Data Validation Reports: This provides a detailed view into the data validation results, including information about any failed tests and any data issues that have been identified.I prefer to store validation results (a JSON object) into a database for further analysis. The complete source code for this article is available in &lt;a href=&#34;https://github.com/saisyam/great-expectations-sample&#34;&gt;GitHub&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&#34;installing-great-expectations&#34;&gt;Installing Great Expectations&lt;/h2&gt;&lt;p&gt;I always prefer to setup a virtual environment for my Python projects. I assume you also do the same. Inside your virutal environment, you can install Great Expectations with pip:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ pip install great_expectations&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;p&gt;Use Python 3.8 and above. Detailed installation steps can be found &lt;a href=&#34;https://docs.greatexpectations.io/docs/guides/setup/installation/local&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&#34;setting-up-the-data-context&#34;&gt;Setting up the Data context&lt;/h2&gt;&lt;p&gt;A typical data context config for filesystem looks like this:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;STORE_FOLDER &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/Users/saisyam/work/github/great-expectations-sample/ge_data&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Setup data config&lt;/span&gt;data_context_config &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; DataContextConfig(    config_version &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,    plugins_directory &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,    config_variables_file_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,    datasources &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {},    stores &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;expectations_store&amp;#34;&lt;/span&gt;: {            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ExpectationsStore&amp;#34;&lt;/span&gt;,            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;store_backend&amp;#34;&lt;/span&gt;: {                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TupleFilesystemStoreBackend&amp;#34;&lt;/span&gt;,                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;base_directory&amp;#34;&lt;/span&gt;: STORE_FOLDER&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/expectations&amp;#34;&lt;/span&gt;            }        },        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;validations_store&amp;#34;&lt;/span&gt;: {            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ValidationsStore&amp;#34;&lt;/span&gt;,            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;store_backend&amp;#34;&lt;/span&gt;: {                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TupleFilesystemStoreBackend&amp;#34;&lt;/span&gt;,                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;base_directory&amp;#34;&lt;/span&gt;: STORE_FOLDER&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/validations&amp;#34;&lt;/span&gt;            }        },        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;checkpoint_store&amp;#34;&lt;/span&gt;: {            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CheckpointStore&amp;#34;&lt;/span&gt;,            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;store_backend&amp;#34;&lt;/span&gt;: {                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TupleFilesystemStoreBackend&amp;#34;&lt;/span&gt;,                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;base_directory&amp;#34;&lt;/span&gt;: STORE_FOLDER&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/checkpoints&amp;#34;&lt;/span&gt;            }        },        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;evaluation_parameter_store&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;EvaluationParameterStore&amp;#34;&lt;/span&gt;}    },    expectations_store_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;expectations_store&amp;#34;&lt;/span&gt;,    validations_store_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;validations_store&amp;#34;&lt;/span&gt;,    evaluation_parameter_store_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;evaluation_parameter_store&amp;#34;&lt;/span&gt;,    checkpoint_store_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;checkpoint_store&amp;#34;&lt;/span&gt;,    data_docs_sites&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local_site&amp;#34;&lt;/span&gt;: {            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteBuilder&amp;#34;&lt;/span&gt;,            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;store_backend&amp;#34;&lt;/span&gt;: {                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TupleFilesystemStoreBackend&amp;#34;&lt;/span&gt;,                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;base_directory&amp;#34;&lt;/span&gt;: STORE_FOLDER&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/data_docs&amp;#34;&lt;/span&gt;,                            },            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;site_index_builder&amp;#34;&lt;/span&gt;: {                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DefaultSiteIndexBuilder&amp;#34;&lt;/span&gt;,                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;show_cta_footer&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,            },        }    },    anonymous_usage_statistics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{      &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;enabled&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;    })&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have the config ready, we can set the context with:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;context &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BaseDataContext(project_config &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data_context_config)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;setting-up-data-source&#34;&gt;Setting up data source&lt;/h2&gt;&lt;p&gt;We will setup a Pandas data source and add it to the context&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;datasource_config &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sales_datasource&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Datasource&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;module_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;great_expectations.datasource&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;execution_engine&amp;#34;&lt;/span&gt;: {        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;module_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;great_expectations.execution_engine&amp;#34;&lt;/span&gt;,        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PandasExecutionEngine&amp;#34;&lt;/span&gt;,    },    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data_connectors&amp;#34;&lt;/span&gt;: {        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_runtime_data_connector_name&amp;#34;&lt;/span&gt;: {            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RuntimeDataConnector&amp;#34;&lt;/span&gt;,            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;module_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;great_expectations.datasource.data_connector&amp;#34;&lt;/span&gt;,            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch_identifiers&amp;#34;&lt;/span&gt;: [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_identifier_name&amp;#34;&lt;/span&gt;],        },    },}context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_datasource(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;datasource_config)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;creating-expectation-suite-and-add-expectations-to-it&#34;&gt;Creating Expectation suite and add Expectations to it&lt;/h2&gt;&lt;p&gt;Now it&amp;rsquo;s time to create an Expectation suite and add expectations to the suite:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create expectations suite and add expectations&lt;/span&gt;suite &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create_expectation_suite(expectation_suite_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sales_suite&amp;#34;&lt;/span&gt;, overwrite_existing&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&lt;span style=&#34;color:#75715e&#34;&gt;# Add expectations&lt;/span&gt;expectation_config_1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ExpectationConfiguration(    expectation_type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;expect_column_values_to_be_in_set&amp;#34;&lt;/span&gt;,    kwargs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;column&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;product_group&amp;#34;&lt;/span&gt;,        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value_set&amp;#34;&lt;/span&gt;: [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PG1&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PG2&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PG3&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PG4&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PG5&amp;#34;&lt;/span&gt;]    }) suite&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_expectation(expectation_configuration&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;expectation_config_1)expectation_config_2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ExpectationConfiguration(    expectation_type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;expect_column_values_to_be_unique&amp;#34;&lt;/span&gt;,    kwargs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;column&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;    }) suite&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_expectation(expectation_configuration&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;expectation_config_2)context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save_expectation_suite(suite, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sales_suite&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we have everything ready to run the expectations on dataset.&lt;/p&gt;&lt;h2 id=&#34;create-dataset-and-run-checkpoint&#34;&gt;Create dataset and run checkpoint&lt;/h2&gt;&lt;p&gt;We will use a &lt;a href=&#34;https://github.com/saisyam/great-expectations-sample/blob/master/sales.csv&#34;&gt;sample sales dataset&lt;/a&gt;. Create a batch request and run the checkpoint. We will use all the default parameters from Great Expectations.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# load and validate data&lt;/span&gt;df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;./sales.csv&amp;#34;&lt;/span&gt;)batch_request &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RuntimeBatchRequest(    datasource_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sales_datasource&amp;#34;&lt;/span&gt;,    data_connector_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_runtime_data_connector_name&amp;#34;&lt;/span&gt;,    data_asset_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;product_sales&amp;#34;&lt;/span&gt;,    runtime_parameters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch_data&amp;#34;&lt;/span&gt;:df},    batch_identifiers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_identifier_name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default_identifier&amp;#34;&lt;/span&gt;})checkpoint_config &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;product_sales_checkpoint&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;config_version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SimpleCheckpoint&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;expectation_suite_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sales_suite&amp;#34;&lt;/span&gt;}context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_checkpoint(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;checkpoint_config)results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; context&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run_checkpoint(    checkpoint_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;product_sales_checkpoint&amp;#34;&lt;/span&gt;,    validations&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[        {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch_request&amp;#34;&lt;/span&gt;: batch_request}    ])print(results)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p class=&#34;img-fluid&#34;&gt;The above code will print the validation results as a Python dict. As we have enabled data docs in our config, you will see a &lt;code&gt;data_docs&lt;/code&gt; folder under &lt;code&gt;STORE_FOLDER&lt;/code&gt; where the HTML output is stored. Each run will create a new HTML file under &lt;code&gt;validations&lt;/code&gt; folder inside &lt;code&gt;data_docs&lt;/code&gt;. The sample HTML file will look like:&lt;img src=&#34;https://saisyam.com/great_expectations_html_output.jpg&#34; alt=&#34;Great Expectation validation results&#34; title=&#34;Great Expectation validation results&#34;&gt;&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;We have learnt how to setup and run Great Expectations on a dataset. Great Expectations provides an excellent documentation on how to use different stores (AWS S3, Azure Blob and Google storage) to store expectations and results. The sample code is available in GitHub and you can extend it with different stores. Thanks for reading.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Deploy Python FastAPI Service on Kubernetes MiniKube</title>
       <link>https://saisyam.com/deploy-python-fastapi-service-on-kubernetes-minikube/</link>
       <pubDate>Mon, 30 May 2022 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/deploy-python-fastapi-service-on-kubernetes-minikube/</guid>
       <description>&lt;p&gt;In this article we will build a Python FastAPI application with a single API which will return the sentiment (Postivie, Negative or Neutral) of the text given as input using &lt;a href=&#34;https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/&#34;&gt;Vader Sentiment Analysis&lt;/a&gt;. We will deploy the service in Kubernetes locally using &lt;code&gt;minikube&lt;/code&gt;. If you are new to FastAPI please refer &lt;a href=&#34;https://fastapi.tiangolo.com/&#34;&gt;here&lt;/a&gt;. If you want to install &lt;code&gt;minikube&lt;/code&gt; refer &lt;a href=&#34;https://minikube.sigs.k8s.io/docs/start/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Installing &lt;code&gt;minikube&lt;/code&gt; is out-of-scope of this article.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#build-sentiment-service-api&#34;&gt;Build Sentiment service API&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#build-the-docker-in-minikube&#34;&gt;Build the Docker in minikube&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#run-our-application&#34;&gt;Run our application&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#test-our-application&#34;&gt;Test our application&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;build-sentiment-service-api&#34;&gt;Build Sentiment service API&lt;/h2&gt;&lt;p&gt;This application contains a single API which will return the sentiment of the text provided as input. The other API we have is to check the health of the application. You can download the complete source code of this application from my Github &lt;a href=&#34;https://github.com/saisyam/vader-sentiment-service&#34;&gt;repo&lt;/a&gt;. Run the following commands to execute the application locally:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ git clone https://github.com/saisyam/vader-sentiment-service.git$ cd  vader-sentiment-service$ python3 -m venv .venv --prompt ss$ source .venv/bin/activate$ pip install pip --upgrade$ pip install -r requirements.txt$ uvicorn service.main:app --reload&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Go to &lt;code&gt;http://127.0.0.1:8000/docs&lt;/code&gt; to see the Swagger API and try the &lt;code&gt;sentiment&lt;/code&gt; API.&lt;/p&gt;&lt;p&gt;&lt;img src=&#34;../vader-sentiment-post-swagger.jpg&#34; alt=&#34;Vader sentiment service&#34;&gt;&lt;/p&gt;&lt;h2 id=&#34;build-the-docker-in-minikube&#34;&gt;Build the Docker in minikube&lt;/h2&gt;&lt;p&gt;There are multiple ways to push the docker image into &lt;code&gt;minikube&lt;/code&gt;. Refer this &lt;a href=&#34;https://minikube.sigs.k8s.io/docs/handbook/pushing/&#34;&gt;link&lt;/a&gt; for more information. I have used the first one &lt;a href=&#34;https://minikube.sigs.k8s.io/docs/handbook/pushing/#1-pushing-directly-to-the-in-cluster-docker-daemon-docker-env&#34;&gt;Pushing directly to the in-cluster Docker daemon (docker-env)&lt;/a&gt;. It worked for me. I built my docker images as:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ cd vader-sentiment-service$ docker build -t vader-sentiment .&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The docker image build directly in to &lt;code&gt;minikube&lt;/code&gt;.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;run-our-application&#34;&gt;Run our application&lt;/h2&gt;&lt;p&gt;Now it&amp;rsquo;s time to create &lt;code&gt;deployment&lt;/code&gt; and &lt;code&gt;service&lt;/code&gt; to run our docker in &lt;code&gt;minikube&lt;/code&gt;. We will keep it simple for this article. Will explore more options on scaling the application in future articles. The &lt;code&gt;api.yaml&lt;/code&gt; file in the Github repo contain &lt;code&gt;service&lt;/code&gt; and &lt;code&gt;deployment&lt;/code&gt; template.&lt;/p&gt;&lt;p&gt;Service template&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# vader-sentiment LoadBalancer Service&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Enables the pods in a deployment to be accessible from outside the cluster&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vader-sentiment-svc&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vader-sentiment&lt;/span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TCP&amp;#34;&lt;/span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;LoadBalancer&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Deployment template - we will have only one replica for now.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# vader-sentiment Deployment&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Defines the deployment of the app running in a pod on any worker node&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;apps/v1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Deployment&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vader-sentiment&lt;/span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vader-sentiment&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:  &lt;span style=&#34;color:#f92672&#34;&gt;replicas&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:    &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:      &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vader-sentiment&lt;/span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:      &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:        &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vader-sentiment&lt;/span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:        - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vader-sentiment&lt;/span&gt;          &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vader-sentiment:latest&lt;/span&gt;          &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:            - &lt;span style=&#34;color:#f92672&#34;&gt;containerPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;          &lt;span style=&#34;color:#f92672&#34;&gt;imagePullPolicy&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IfNotPresent&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Use the below command to deploy service:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ kubectl apply -f api.yaml service/vader-sentiment-svc createddeployment.apps/vader-sentiment created$ kubectl get podsNAME                              READY   STATUS    RESTARTS   AGEvader-sentiment-8f5bfc566-wk9p9   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          2s&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Make sure you have the status running as shown above. Now we want the public IP so that we can test our API. Run the following command to get it:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ kubectl get svc vader-sentiment-svcNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP   PORT&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;          AGEvader-sentiment-svc   LoadBalancer   10.110.16.243   &amp;lt;pending&amp;gt;     8080:30498/TCP   25s&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;EXTERNAL-IP&lt;/code&gt; is showing as &lt;code&gt;&amp;lt;pending&amp;gt;&lt;/code&gt;. Open another terminal and run the command:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ minikube tunnelStatus:machine: minikubepid: &lt;span style=&#34;color:#ae81ff&#34;&gt;1612721&lt;/span&gt;route: 10.96.0.0/12 -&amp;gt; 192.168.49.2minikube: Runningservices: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;vader-sentiment-svc&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;    errors: minikube: no errorsrouter: no errorsloadbalancer emulator: no errors&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now again run the &lt;code&gt;get svc&lt;/code&gt; command:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ kubectl get svc vader-sentiment-svcNAME                  TYPE           CLUSTER-IP      EXTERNAL-IP     PORT&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;          AGEvader-sentiment-svc   LoadBalancer   10.110.16.243   10.110.16.243   8080:30498/TCP   22m&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now you see the &lt;code&gt;EXTERNAL-IP&lt;/code&gt;. Ofcourse, the CLUSTER-IP and EXTERNAL-IP are same as we are running Kubernetes locally. Our application is deployed in &lt;code&gt;minikube&lt;/code&gt; successfully.&lt;/p&gt;&lt;h2 id=&#34;test-our-application&#34;&gt;Test our application&lt;/h2&gt;&lt;p&gt;I use cURL command to test my APIs. You can use postman as well. To test the sentiment API use the following cURL command:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;curl -X &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;POST&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://10.110.16.243:8080/api/v1/sentiment&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accept: application/json&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Content-Type: application/json&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  -d &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  &amp;#34;sentence&amp;#34;: &amp;#34;The ice cream tastes delicious&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You will get the following response:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sentence&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;The ice cream tastes delicious&amp;#34;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sentiment&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Positive&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;We have learnt how to deploy a simple service built with Python FastAPI into a Kubernetes (minikube) cluster using Docker. In future articles we will see how to deploy the same service on to public clouds like AWS, GCP and Azure. Thank you for reading.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Sentiment Analysis using Python Vader</title>
       <link>https://saisyam.com/sentiment-analysis-using-python-vader/</link>
       <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
       
       <guid>https://saisyam.com/sentiment-analysis-using-python-vader/</guid>
       <description>&lt;p&gt;Sentiment analysis is a process of determining whether the given emotion (text) is postivie, negative or neutral. Sentiment Analysis is useful in identifying customers emotions for a service or product. In this article we will perform sentiment analysis on restaurant reviews.&lt;/p&gt;&lt;div id=&#34;toc&#34;&gt;    &lt;nav id=&#34;TableOfContents&#34;&gt;  &lt;ul&gt;    &lt;li&gt;&lt;a href=&#34;#installing-vader-sentiment-analysis-tool&#34;&gt;Installing VADER Sentiment Analysis Tool&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#performing-sentiment-analysis&#34;&gt;Performing Sentiment Analysis&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#what-is-missing-with-vader-sentiment-analysis&#34;&gt;What is missing with VADER Sentiment Analysis?&lt;/a&gt;&lt;/li&gt;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;  &lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;p&gt;VADER(Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. VADER not only tells about the positivity and negativity score but also tells us about how positive or negative it is. VADER sentimental analysis relies on a dictionary that maps lexical features to emotion intensities known as sentiment scores. The sentiment score of a text can be obtained by summing up the intensity of each word in the text.&lt;/p&gt;&lt;p&gt;For example, words like, &lt;em&gt;&amp;lsquo;happy&amp;rsquo;, &amp;lsquo;awesome&amp;rsquo;, &amp;lsquo;good&amp;rsquo;&lt;/em&gt; all convey positive emotion. VADER is intelligent enough to understand the context of these words. For example, &lt;em&gt;&amp;ldquo;Food is not good&amp;rdquo;&lt;/em&gt; is considered negative. If also understands the emphasis of capitalization and punctuation. For example, &lt;em&gt;&amp;ldquo;AWESOME&amp;rdquo;&lt;/em&gt; (capital letters) will represent the high intensity of positivity.&lt;/p&gt;&lt;h2 id=&#34;installing-vader-sentiment-analysis-tool&#34;&gt;Installing VADER Sentiment Analysis Tool&lt;/h2&gt;&lt;p&gt;VADER is available as part of NLTK Python package. I use &lt;code&gt;pip3&lt;/code&gt; to install Python packages. Below command will install &lt;code&gt;nltk&lt;/code&gt;.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ pip3 install nltk&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once &lt;code&gt;nltk&lt;/code&gt; is installed, we need to download the &lt;code&gt;vader lexicon&lt;/code&gt;.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; nltk&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; nltk&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;download(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vader_lexicon&amp;#39;&lt;/span&gt;)[nltk_data] Downloading package vader_lexicon to[nltk_data]     &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;home&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;saisyam&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;nltk_data&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will install required data for using VADER sentiment analysis.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;performing-sentiment-analysis&#34;&gt;Performing Sentiment Analysis&lt;/h2&gt;&lt;p&gt;We have everything installed to perform the sentiment analysis. Let&amp;rsquo;s use VADER to find the sentiment of the following review:&lt;/p&gt;&lt;p&gt;&lt;em&gt;&amp;ldquo;Pretty pricey but the lamb burger ($25) is beyond amazing. Definitely worth it. So, so good.&amp;quot;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;The following code will perform the sentiment analysis.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.sentiment.vader &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SentimentIntensityAnalyzersia &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SentimentIntensityAnalyzer()text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Pretty pricey but the lamb burger ($25) is beyond amazing. Definitely worth it. So, so good.&amp;#34;&lt;/span&gt;sia&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polarity_scores(text)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When we run the above code we get the following output:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;: 0.0, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;neu&amp;#39;&lt;/span&gt;: 0.369, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;: 0.631, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;compound&amp;#39;&lt;/span&gt;: 0.963&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;VADER&amp;rsquo;s &lt;code&gt;SentimentIntensityAnalyzer()&lt;/code&gt; takes in a string and returns a dictionary of scores in each of four categories:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;negative&lt;/li&gt;&lt;li&gt;neutral&lt;/li&gt;&lt;li&gt;positive&lt;/li&gt;&lt;li&gt;compound (computed by normalizing the scores above)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The above result says that the emotion in the given review is &lt;em&gt;positive&lt;/em&gt;. Let&amp;rsquo;s look at the other review:&lt;em&gt;&amp;ldquo;The food is so good. The service is so bad.&amp;quot;&lt;/em&gt;When we run the above code for the given text, the output is:&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;: 0.277, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;neu&amp;#39;&lt;/span&gt;: 0.493, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;: 0.23, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;compound&amp;#39;&lt;/span&gt;: -0.1901&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The review has two polarities. The customer is appreciating the food but not satisfied with the service. To judge whether the review is positive or negative we use the below logic.&lt;/p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; compound &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;:    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Positive&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; compound &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;:    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Negative&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Neutral&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Which says the above review is &lt;em&gt;negative&lt;/em&gt;.&lt;/p&gt;&lt;script async src=&#34;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&#34;&gt;&lt;/script&gt;&lt;ins class=&#34;adsbygoogle&#34;     style=&#34;display:block; text-align:center;&#34;     data-ad-layout=&#34;in-article&#34;     data-ad-format=&#34;fluid&#34;     data-ad-client=&#34;ca-pub-0206245742790279&#34;     data-ad-slot=&#34;3890452391&#34;&gt;&lt;/ins&gt;&lt;script&gt;     (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt;&lt;h2 id=&#34;what-is-missing-with-vader-sentiment-analysis&#34;&gt;What is missing with VADER Sentiment Analysis?&lt;/h2&gt;&lt;p&gt;VADER only tries to get the emotion (postivie/negative/neutral) out of text. It won&amp;rsquo;t care about the aspect. For example, the review,&lt;em&gt;&amp;ldquo;The food is so good. The service is so bad.&amp;quot;&lt;/em&gt; is &lt;em&gt;negative&lt;/em&gt; from the &lt;code&gt;service&lt;/code&gt; aspect but &lt;em&gt;postive&lt;/em&gt; from the &lt;code&gt;food&lt;/code&gt; aspect. If we identify sentiment based on aspects then it will be much more helpful. This is called &lt;em&gt;Aspect based Sentiment Analysis&lt;/em&gt;.&lt;/p&gt;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In this post we have learnt how to find whether the text is positive, negative or neutral using Python based VADER Sentiment Analysis. We also discussed the next level of sentiment analysis based on aspects. In the next article we will see how we can identify aspects for a given industry or domain and implement the sentiment analysis based on aspects.&lt;/p&gt;</description>
     </item>
   
 </channel>
</rss>
